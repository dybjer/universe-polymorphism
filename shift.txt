TENTATIVE TITLE: Polynomial decidability of sup-lattice theory with
successor function.

Let C be a set of clauses with variables in V. 
C is closed under shifting upwards means that if A->a in C,
then also A+k -> a+k in C, for all k>0. Predecessor clauses are
clauses x+k+1 -> x+k for all x in V and k in N.
For W subset of V, C_W is the subset of C with only variables
in W; C->W is the subset of C of clauses with conclusion on W.

The gain of a clause x1+k1 + ... + xn+kn -> x+k is k minus the 
minimum of {k1, ... ,kn}. The gain is invariant under shifting.
MAXGAIN is the maximum of the gains of clauses, a finite number
when the clauses come from finitely many lattice constraints. 
A fortiori, for clauses of the form ...,xi+li,...,Y -> x+k in C,
we have k <= min(li) + MAXGAIN.

Let N+ denote N,∞. If f,g: V -> N+ are models of C, so is min(f,g). 

Lemma: Let V be a set of variables.
Let C be a set of clauses with variables in V, 
closed under shifting upwards,
containing all predecessor clauses, 
and with all gains <= MAXGAIN. 
Let W be a strict subset of V such that 
for any f : W -> N+ we can compute 
the least g >= f that is a model of C_W.
Then for any f: V -> N+ with f(V-W) subset of N we can compute
the least h >= f that is a model of C->W.

Proof: Let conditions be as stated in the lemma.
Clearly, h coincides with f on V-W, so we focus on its values on W.
For any f: V -> N+, let f_W be its restriction to W.
Then we can compute the least g_f >= f_W that is a model of C_W.
Now we look at clauses in C->W - C_W. Such clauses are of
the form X,Y -> w+k with X non-empty and based on V-W and Y
based on W. If X = ...,xi+li,... is activated in f, 
then k <= min(f(xi)) + MAXGAIN <= max(f(V-W)) + MAXGAIN.
Using that f(V-W) is a subset of N, we do induction on 

M(g_f) := Sum_{w in W}  max(0, max(f(V-W)) + MAXGAIN - g_f(w)).   

Base: if M(g_f)=0, then we can take h=g_f on W and we are done.
(All clauses in C->W are satisfied in this case.)

Step: let M(g_f)>0 and assume OK for all smaller values.
If all clauses in C->W - C_W are satisfied, we are again done.
If not, we can improve some value g_f(w) using a clause in C->W - C_W.
Say that we can infer the value g_f(w)+k+1 for w using values of f 
on V-W and values of g_f on W. Define f' : V -> N+ by 

f'(x)=f(x) for x in V-W, 
f'(y)= g_f(y) for y in W-w and 
f'(w) = g_f(w)+k+1. 

Then M(g_f') < M(g_f) and we can apply the IH to f'. 
The resulting h for f' also works for f.
QED

Remark: given f: V -> N+, any variable v with f(v)=∞ can be
eliminated from the clause set C: all clauses ... -> v+k
can be left out, and all atoms v+k in ...,v+k,... -> ...
can be deleted from the remaining clauses. 
If we get a clause empty -> x+k, then we can infer f(x)=∞
and continue the simplification process.
Under this simplification, MAXGAIN is respected.
In a proof for all V by induction on |V| we can (and will) 
apply the IH immediately to the simplified situation.


THM: Let V be a non-empty set of variables.
Let C be a set of clauses with variables in V, 
closed under shifting upwards,
containing all predecessor clauses, 
and with all gains <= MAXGAIN.
Then for any f : V -> N+ we can compute 
the least g >= f that is a model of C. 

Proof by induction on |V|.

Base: V = x. Clauses in C are of the form ...,x+ki,... -> x+k.
Such clauses are trivial if max(ki)>=k.
If all clauses in C are trivial, take g(x) = f(x).
Otherwise, any non-trivial clause is of the form 
x+max(ki) -> x+max(ki)+l+1 (ignoring trivial atoms on the left). 
Then we take g(x) = ∞ if f(x)>=max(ki) for some non-trivial
clause, and g(x) = f(x) otherwise.

Step: Let |V|> 1 and assume OK for smaller V. 
If f(v)=∞ for some v in V, simplify C to C' and apply the IH.
Applying the IH is justified since C' has fewer variables,
and satisfies all conditions (in particular wrt MAXGAIN).
The h for C' is extended by value(s) ∞ for the eliminated 
variable(s) to a minimal model >= f of C. 

Assume now f : V -> N.
We compute first the subset of variables x of V whose value f(x)
can be improved in one step. For any x in V, we look at clauses

(*)  A -> x+k, A activated in f, yielding result k for x.

Let g(x) be the maximum of f(x) and the results for x, as obtained
above, and let W be the set of all x in V such that g(x) > f(x).

If W is empty we are done since then f itself is a model of C.

If W = V we are done since then h(x) = ∞ for all x in V is the 
least h >= f that is a model of C. 
(If V+f |- V+f+1, then V+f |- V+f+k for all k>0.)

Otherwise, W is a non-empty strict subset of V and we can apply
the IH to W, C_W and g_W to satisfy the condition of the lemma.
Hence we get the conclusion of the lemma: since g(V-W)=f(V-W) is
a subset of N, we can compute the least h>=g that is a model of C->W.

The latter h coincides with g and f on V-W. 
If h(w) = ∞ for some w in W, then we simplify and apply the IH 
to the smaller V', C' and restricted h. Then we are
done as described in the first paragraph of the step case.

Assume now h: V -> N. There are only two possibilities left:

- all clauses in C are satified by h and we are done.

- not all clauses in C are satisfied by h, and in this case any 
unsatisfied clauses must have conclusion y+k with y in V-W.
Improve maximally all such y in the way described in (*) above,
with h instead of f (to keep all work done already).
Add y's that can be improved to W to obtain W' and proceed
in a similar way as after (*). This terminates since we exhaust V.
QED

Example 1.

y -> x with n(x)=1, n(y)=9. n(x) can be improved to m(x)=9.
So we have m(V,n())(x) = m(V,n())(y) = 9.
Recursive call with W=x and empty set of clauses, nothing changes, done.

Example 2.

a->b+1, b->c+1, c->d+1, d+1->e, e+1->f, f+1->g, with n()= 0000000.

W=bcd, m() = 0111000 with b->c+1, c->d+1

  Recursive call with m(W,n()= 0122000 and c->d+1

     Recursive call with  0123000 and empty

Return 0123000

W'=bcdef, 0123210 model for b->c+1, c->d+1, d+1->e, e+1->f 

Return 0123210, model for all clauses



-----------------------------------------------------------


Two examples (without cumulativity, but type 1 in any U_x).

1.          |- U_x : U_x     not well-typed: x = x+1 is a loop

2.   A: U_x |- Id U_z ((U_y -> 1) -> A) A   well/ill-typed? Analysis:

((U_y -> 1) -> A) : U_((y+1) \/ x)  and A: U_x, 

so we must solve the level constraints ((y+1) \/ x) = z and x = z. 
This does not create a loop (e.g. in Z, with x = z = 1, y = 0). So this example is fine.


 We write the type corresponding to 2 as

 (1)    {x y : Level} -> [ y+1 <= x ] -> (A : U_x) -> Id U_x ((U_y -> 1) -> A) A

(this type should be inhabited with univalence)

 The difference with what is in Agda now is that we have to -solve- the constraint
 ((y+1) \/ x) = x solution  x = z \/ (y+1)   z arbitrary,  and write a type

 (2)    {z y : Level} -> (A : U_{z\/(y+1)}) -> Id U_{z\/(y+1)} ((U_y -> 1) -> A) A


 In general a constraint problem may not have a most general solution but several independent
 solution so we have to duplicate statements in an artifical way

 More importantly, one can argue that (1) expresses in a clearer way what is going on than (2)




 When I instantiate a proof of (1) with concrete levels l and m respectively for x and y
 we will have to decide if  m+1 <= l (given other constraints)
 so: we have to decide if a constraint is a consequence of other constraint

 Also we have to decide if a constraint is "consistent", i.e. does not imply some loops
 a level l such that l+1 <= l

 In general, we must solve constraints in the theory 
of sup semi-lattice with one unary operation x+ and two extra equational axioms for +:

(x\/y)+  = x+ \/ y+

x \/ x+ =   x+

 Claim: this theory is decidable and we can detect loops.

Shorthand: s >= t for s \/ t = s, so the last one is x <= x+1

Change of narrative: from lattices to Horn clauses (`equivalent')

Example: ((y+1) \/ x) = x translates to y+1, x -> x and x -> x and x -> y+1.
Note that only the last one is informative, indeed it expresses x >= y+1.

Generally L -> t means that sup(L) >= t.

WLOG (!) we start from a set of clauses of the form   A -> a  where all 
atoms in A,a are of the form x or x+1, and A non empty

We write B |- b   if we can derive b from B using the `shifted' clauses
A +n -> a+n   and   x+n+1 -> x+n (the last one comes from x <= x+1)


THM:   we can find U subset of V such that U |- x+1 for all x in U
and n(x) for x in V-U such that V |- x+n iff n <= n(x) for x in V-U

U may be empty  and we can have U = V in which case we have
V |- x+1 for all x in V

This means that we have a complete description of all consequences of V: 
we have V |- x+ n  for all n if x in U and V |- x+ n for n <= n(x) for x in V-U



 Example: x+1,y -> x+1   x,y+1 -> y+1

 V = x, y
 W empty

 We put n(x) = n(y) = 0 and U is empty

 Example:   x+1 -> y       y -> z+1     z -> x+1

 V = x, y, z
 W = x, z

 There is only one clause  z -> x+1 involving only z and x
 The consequences of z+1, x+1  are  z+1, x+2

 The clause  x+2 -> y+1 gets activated
 We add y to W  and we have W = V = U = x,y,z

 Example:   y+1 -> x,   y -> y+1,   z -> x

 We have W = y and U = W
 The clause y+1 -> x gets activated, we add x
 We have W = x,y and U = W = x,y
 We have z in V-W and n(z) = 0

  Example:   x+1 -> t,    y+1 -> x,   y -> y+1

 We have W = y and U = W
 The clause y+1 -> x gets activated, we add x
 We have W = x,y and U = W 
 The clause x+1 -> t gets activated, we add t
 We have W = x,y,t and U = W = V = x,y,t





PROOF of THM: by induction on |V|

If V has only one variable we
 either have no non-trivial clause in which case U = empty and n(x) = 0 
 or the only non-trivial clause is x -> x+1 and then U = V

Assume V has more than one variable and the theorem holds for all set
of variables < |V|

We look at all clauses of the form A -> x+1 where all atoms in A are of the
form y in V

If there is no such clause, we have U = empty and n(x) = 0 for all x in V

Otherwise we let W be the (non-empty) set of x such that 
we have a clause of this form of conclusion x+1

(*) If W = V then we have U = V

If |W| < |V|, by induction we compute all consequences of W+1 using only
clauses that mention only elements in W
we compute U and n(x) for x in W-U

A clause A -> z+1 with z in V-W gets activated if we have the following
-if x is in A we require nothing (since x in V, so V |- x), and
-if x+1 is in A we have x in W (then W |- x+1, so V |- x+1), and 
-if x+2 is in A we have x in U or n(x) >= 2 (then W |- x+2, so V |- x+2)

If such a clause gets activated we know that we have V |- z+1

If there is no clause  A -> z+1,  z in V-W, which gets activated 
we have computed all consequences of V: we add n(z) = 0 for z in V-W,
and we take the U for V the same as the U for W, both n(_) and U from IH.
This is because the clauses A -> x+1, x in W, where there are some 
variables in V-W appearing in A cannot produce new consequences
(This is subtle: if x in U then already W |- x+k for all k (by IH). 
If x in W-U, then n(x)>=1 and x+n(x)+1 requires a clause with a 
variable y in V-W, but n(z)=0 for z in V-W. Not possible because
of bandwith/gain <= 1. Better elaboration:

We have x in W-U  and we try to see if we can use a clause involving other
variables than only variables in W to derive   x + n(x) + 1.
This clause would have the form  A |-  x   or   A |- x+1
and we have  y or y+1 in A   with y in V-W   so  A = B, y   or   A = B, y+1
We are thus wondering if we can activate

 B + n(x) +1 ,   y + n(x) +1   ->    x + n(x) + 1   or
 B + n(x) +1 ,   y + n(x) +2   ->    x + n(x) + 1   or
 B + n(x)    ,   y + n(x)      ->    x + n(x) + 1   or
 B + n(x)    ,   y + n(x) +1   ->    x + n(x) + 1

but this is not possible since we have   n(x) >= 1   and  n(y) = 0 )

If there are some clauses A -> z+1, z in V-W, getting activated
we add to W all these variables and we start again at (*)

At some point we end in the situation with no activated clauses,
or we have W = V and we have U = V.

QED

 This describes completely the sup + lattice generated by the given
 constraints: in general we have A |- a iff  a <= sup A

 In some cases, it is enough to consider the linearly ordered model
 of integers

------------------- e-mail 12.05.20---completeness---------------------

Thinking more about it (and after the discussion with Marc) we do have 
completeness and this is a purely proof theoretical result.

On one side we have a finitely presented sup lattice with unary 
operation t+ satisfying

 x+ \/ x =  x+                  (x\/y)+ = x+ \/ y+

 We consider a presentation with finitely many variables V and relations t = u

 Given the rules, we have that any term is of the form x1+n1 \/ … \/ xk+nk

 On the other side we reformulate  this as a Horn clause theory

 We add     x+n+1 -> x+n   and we rewrite the relations t = u as
t <= u and u <= t
 We rewrite  x1+n1 \/ … \/ xk+nk <= u    as   x1+n1 <= u, …, xk+nk <= u

 x+n <= y1+m1 \/ … \/ yl+ml  is rewritten as  y1+m1+k,…,yl+ml+k -> x+n+k
for all k

 We define  then A |- a  if we can derive  A -> a from this Horn clause theory

 Theorem:   we have    x+n <= y1+m1 \/ … \/ yl+ml  in the f.p. lattice iff
y1+m1,..,yl+ml |- x+n

 It is standard that we have a sup lattice by taking as elements formal sups
y1+m1\/…\/yl+ml   and equality     x1+n1\/…\/xk+nk = y1+m1\/…\/yl+ml   
iff   x1+n1, …., xk+nk |- yj + mj    and y1+m1,…,yl+ml |- xi+ni

 We then only have to check that we can define a (+1) operation without
ambiguity and this is clear since

   x1+n1\/…\/xk+nk = y1+m1\/…\/yl+ml   

implies

   x1+n1+1\/…\/xk+nk+1 = y1+m1+1\/…\/yl+ml+1



 Here is an example:  the only relation is   y \/ x = x+

 This does not imply    x = x+

 Marc had a -finite- counter model with 3 points (can be improved to 2 points)

 The f.p. lattice for this relation gives another counterexample which is 
infinite: it has for elements  x+k, y+l   with the operation

   x+k \/ x+l = x+max(k, l)
   y+k \/ y+l = y+max(k, l)

   x+k \/ y+l =    x+l+1    if k<= l
   x+k \/ y+l =    x+k       if l < k


  Another example is the lattice with   x+ = y+
 Then the f.p. lattice has elements  x, y and x+n for n>0.
 
 Thierry

-----------------------------------------------------------


COR of THM:  Consider -∞,Z with Z ordered as usual and -∞ < n for all z in Z.
Consider max as interpretation of \/, the usual +1 on Z  and  -∞+1 = -∞
as interpretation of successor. 
Then we have a (\/,+1) semi-lattice (since we don't require x+1 > x).
Define M(x) = -∞ for all x in U and M(x)= -n(x) for x in V-U.
Then M satisfies all constraints sup(A) >= a, for each A -> a in the set of clauses.

PROOF: write A -> a as X,Y+1 -> z+ℓ, where ℓ=0,1 (ℓ can actually be arbitrary).

To prove: max(M(X),M(Y)+1) >= M(z)+ℓ.

If z in U this is trivial. If X and Y are subsets of U, then also z in U.
(Proof: U |- u+1 for all u in U, so U |- u+k for all k in Z and u in U,
so U |- z+k for all k in Z by the clause X,Y+1 -> z+ℓ, so z in U.)

Hence we may assume z not in U and (X + Y) - U non-empty. Since M(u) = -∞ 
for all u in U, we assume wlog that X and Y do not overlap with U.
In that case we have that max(M(X),M(Y)+1) >= M(z)+ℓ
is equivalent to min(n(X),n(Y)-1) <= n(z)-ℓ. Distinguish now two cases:

- Case lhs = n(xi), then X+n(xi),Y+n(xi)+1 -> z+n(xi)+ℓ is activated,
  so n(z) >= n(xi)+ℓ.
- Case lhs = n(yj)-1, then X+n(yj)-1,Y+n(yj) -> z+n(yj)-1+ℓ is activated,
  so n(z) >= n(yj)-1+ℓ.

In both cases we are done. QED


As an application of the above corollary we get a limited completeness result:

For all x in V and k in Z:

sup(V) >= x+k is provable from the lattice constraints  iff  V |- x+k.

Proof. 

"if" is easy, all steps in the proof of V |- x+k can be mimicked in lattice theory.

For "only if", distinguish two cases:

1. x in U. Recall U |- u+1 for all u in U, so U |- u+k for all k in Z.
So, if x in U, then U |- x+k, so V |- x+k. 

2. x in V-U. If k <= n(x), then V |- x+k follows from the theorem. 
If k > n(x), then in the model of the corollary we have 
on one hand M(x)+k = -n(x)+k > 0.
On the other hand, max(M(V)) <= 0 since M(z) = -n(z) or -∞.
Hence sup(V) >= x+k is false in the model and by soundness
provability of sup(V) >= x+k in case k > n(x) is absurd.


Example: x \/ y >= x+1 does not prove y >= x+1.

Consider x,y -> x+1 and start from y. We get nothing by y, not x+1.

Countermodel x, y, x\/y take for +1 the identity function.

We have sup(x,y) >= x = x+1, but not y >= x+1 = x.

 The syntactical or "free" model generated by x, y and x\/y = x+1 is infinite
 and another counter-model showing that we don't have y >= x+1



MORE EXAMPLES: in the Prolog files (slightly different algorithm)







-------------------------------------------------

I would like to have a result about sup semi lattice with -only- the equational rules

1 + (x\/y) = (1+x) \/ (1+y)

 x \/ (1+x) =    1+x


The claim would be that

(1) a finitely presented such lattice is decidable

(2) we can decide and find if such a f.p. lattice contains a such that   a+1 = a

This should be all that is needed to check that a finite number of constraints does not
imply any “loop” and to decide if a constraint is a consequence of the given constraints

The proofs of (1)  and (2), if I am not mistaken, are variations on Marc’s algorithm.

We have a finite number of constraints   X1 -> a1, …, Xn -> an   with a gain/bandwith <= 1

X -> a      X non empty finite set of terms, a term
a term     a is of the form  x + n    n in Z, x atom


 a+1 -> a
 X -> a    iff    X+1 -> a+1


We start from assigning the value 0 to all variables We proceed as in Marc’s algorithm

This is like trying to enumerate all consequences of V = x1,..,xm

Either 

-all variables get increased by at least 1   then we have  a loop with  a = sup V   we have a = a+1

-or we find a “gap”: we have g and U subset V non empty
 all variables in U has a value > g
 all variables in V-U  have a value < g
 we have only consequences increasing values in U
 then we have a loop with a = sup U

-or we don’t increase the variables any more: we don’t have a loop


Note that in the second case, for all atom x in U  we have that all x+n are consequences 
What we can do then is to take away all variables in U from X1 -> a1,.., Xn -> an
and we get a set of constraints that is in the third case


 Example (Marc):   y+1 -> x,   y -> y+1,   z -> x

 x, y
 y+1
 y+2
 x+1
 y+3
 x+2
 ...


  Example:   x+1 -> t,    y+1 -> x,   y -> y+1

 x, y, t
 y+1
 y+2
 x+1
 y+3
 x+2
 y+4
 t+1


To take a trivial example

   x, z -> t+1      x, y -> x+1       x, y -> y+1

we have V = x,y,z,t

  t+1,   x+1,   y+1,   x+2, y+2, ....


We get U = x,y

If we take away   the variables in U we get the system       z -> t+1

And the only consequences   of   z, t    are   z + n   n<=0   and t+n   n <= 1

I need

 -only variables in U are increased infinitely often
 -if we take away the variables in U


This implies that    we can decide     x1, …, xm -> a 
V = x1,…,xm   all atoms
a term




It follows from this that we can decide   any        x1 + k1, .., xm + km -> a
Let
   k = max(k1,..,km)
   l = min(k1,…,km)
   Y = x1 + k1,.., xm +km

We can represent geometrically all consequences of   V+k   and V+l
and the consequences of Y are “in between” these consequences


If we are in the first case, we can deduce a

If we are in the third case a = x+l,  we enumerate
all consequences of x1+k1,…,xm+k and it is bounded above since between consequences of V+k and V+l
so we can decide if a is a consequence

We reduce the second case to the third case by taking away all variables in U.

 I use completeness



And then I also think that we can decide   any   y1 + l1,…,yp+lp -> a    y1,..,yp  subset of V


---------------------------------------


 Some more historical remarks:

 -Hertz introduced this notion of sequent X -> a.
 This influenced Gentzen (and his first paper was exactly about this kind of sequents)

 -Tarski had an equivalent more algebraic presentation in term of consequence relation
(which is presented in Aczel’s paper)

 -It might be Lorenzen who was the first to point out the connection between this kind of sequent
calculus and meet/sup semi lattice

 -when Russell introduced the “doctrine of types” in Appendix B of Principles of Mathematics
(1903) he considers the possibility of the hierarchy of type being indexed by rational numbers!

---------------------------------------

 In this email, I formulate a slight generalisation of what we can do
with Marc’s algorithm. I only state the result without tying to describe the algorithm.
 If correct this is a purely syntactical result (no models).

-----------------------

 First, we recall the well-known propositional Horn clause inference

 We have some atoms a, b, c, …

 We have a finite set of clauses   X1 -> a1,  …, Xn -> an
X1,…,Xn finite sets of atoms

 We write X, a   for   X union {a}

 The inference rules are

 X ->  a         if    a in X
 X’ -> a         if     X -> a   and X subset X’
 X -> b         if      X -> a   and X, a -> b


 The problem is: to decide if a clause X -> a is a consequence
of given clauses X1-> a1,…, Xn -> an



 The algorithm is as follows. We start from X, and we add
all direct consequences: we add ai if Xi subset X and ai not in X
We then get a bigger set X’. We add again all direct consequences
of X’, and so on until we get a fix point X^m

 We then test if a is in X^m
 If it is, X -> a is a consequence of the given clauses
 If it is not, X -> a is not a consequence
 

-------------------------------------


 What we have is a generalization of this algorithm where

 -the atoms are of the form a+n   n integer

 -we add two new inference  rules

             X -> a   iff    X+n -> a+n   n integer

             a+1 -> a


  Here is an example:    the given set of clauses is

 a, b -> a+1
 a, b -> b+1

 Then we have  a, b -> a+n   for any n

 Indeed, starting from a, b  we add a+1 then b+1 then a+2, then b+2 and so on

 Intuitively we have a loop (which corresponds in an inconsistency for universe
levels)


 Another similar example:   a, b -> c    a, c -> b+,   b, c -> a+
 Starting from a, b, we deduce all a+n, b+n, c+n


 In general we can decide  if we can deduce X -> a from X1-> a1,…, Xn -> an
using these rules.

 The idea is also to start from X and to try to deduce all consequences
 The main idea is that we can recognize when there is a loop (using the notion
of gap described in Marc’s message).


