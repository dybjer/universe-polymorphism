%\documentclass[12pt,a4paper]{amsart}
\documentclass[11pt,a4paper]{article}
%\ifx\pdfpageheight\undefined\PassOptionsToPackage{dvips}{graphicx}\else%
%\PassOptionsToPackage{pdftex}{graphicx}
\PassOptionsToPackage{pdftex}{color}
%\fi

%\usepackage{diagrams}

%\usepackage[all]{xy}
\usepackage{url}
\usepackage{verbatim}
\usepackage{latexsym}
\usepackage{amssymb,amstext,amsmath,amsthm}
\usepackage{epsf}
\usepackage{epsfig}
% \usepackage{isolatin1}
\usepackage{a4wide}
\usepackage{verbatim}
\usepackage{proof}
\usepackage{latexsym}
%\usepackage{mytheorems}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}{Lemma}[theorem]
\newtheorem{proposition}{Proposition}[theorem]

\usepackage{float}
\floatstyle{boxed}
\restylefloat{figure}


%%%%%%%%%copied from SymmetryBook by Marc

% hyperref should be the package loaded last
\usepackage[backref=page,
            colorlinks,
            citecolor=linkcolor,
            linkcolor=linkcolor,
            urlcolor=linkcolor,
            unicode,
            pdfauthor={CAS},
            pdftitle={Symmetry},
            pdfsubject={Mathematics},
            pdfkeywords={type theory, group theory, univalence axiom}]{hyperref}
% - except for cleveref!
\usepackage[capitalize]{cleveref}
%\usepackage{xifthen}
\usepackage{xcolor}
\definecolor{linkcolor}{rgb}{0,0,0.5}

%%%%%%%%%
\def\oge{\leavevmode\raise
.3ex\hbox{$\scriptscriptstyle\langle\!\langle\,$}}
\def\feg{\leavevmode\raise
.3ex\hbox{$\scriptscriptstyle\,\rangle\!\rangle$}}

%%%%%%%%%
\newcommand\myfrac[2]{
 \begin{array}{c}
 #1 \\
 \hline \hline
 #2
\end{array}}


\newcommand*{\Scale}[2][4]{\scalebox{#1}{$#2$}}%
\newcommand*{\Resize}[2]{\resizebox{#1}{!}{$#2$}}

\newcommand{\II}{\mathbb{I}}
\newcommand{\refl}{\mathsf{refl}}
\newcommand{\mkbox}[1]{\ensuremath{#1}}


\newcommand{\Id}{\mathsf{Id}}
\newcommand{\conv}{=}
%\newcommand{\conv}{\mathsf{conv}}
\newcommand{\lam}[2]{{\langle}#1{\rangle}#2}
\def\NN{\mathsf{N}}
\def\UU{\mathsf{U}}
\def\JJ{\mathsf{J}}
\def\Level{\mathsf{Level}}
%\def\Type{\hbox{\sf Type}}
\def\ZERO{\mathsf{0}}
\def\SUCC{\mathsf{S}}

\newcommand{\type}{\mathsf{type}}
\newcommand{\N}{\mathsf{N}}
\newcommand{\Set}{\mathsf{Set}}
\newcommand{\El}{\mathsf{El}}
%\newcommand{\U}{\mathsf{U}} clashes with def's in new packages
\newcommand{\T}{\mathsf{T}}
\newcommand{\Usuper}{\UU_{\mathrm{super}}}
\newcommand{\Tsuper}{\T_{\mathrm{super}}}
%\newcommand{\conv}{\mathrm{conv}}
\newcommand{\idtoeq}{\mathsf{idtoeq}}
\newcommand{\isEquiv}{\mathsf{isEquiv}}
\newcommand{\ua}{\mathsf{ua}}
\newcommand{\UA}{\mathsf{UA}}
%\newcommand{\Level}{\mathrm{Level}}
\def\Constraint{\mathsf{Constraint}}
\def\Ordo{\mathcal{O}}

\def\Ctx{\mathrm{Ctx}}
\def\Ty{\mathrm{Ty}}
\def\Tm{\mathrm{Tm}}

\def\CComega{\mathrm{CC}^\omega}
\setlength{\oddsidemargin}{0in} % so, left margin is 1in
\setlength{\textwidth}{6.27in} % so, right margin is 1in
\setlength{\topmargin}{0in} % so, top margin is 1in
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\textheight}{9.19in} % so, foot margin is 1.5in
\setlength{\footskip}{.8in}

% Definition of \placetitle
% Want to do an alternative which takes arguments
% for the names, authors etc.

\newcommand{\natrec}{\mathsf{natrec}}
%\rightfooter{}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\sct}[1]{[\![#1]\!]}



\begin{document}

\title{A Note on Universe Levels}

\author{Marc Bezem, Thierry Coquand, Peter Dybjer, Mart\'in Escard\'o}
\date{}
\maketitle

\begin{abstract}
We present three formal systems for a countable sequence of universes in Martin-Löf type theory. The first system has an externally indexed sequence of universes \`a la Tarski and we present the rules with and without cumulativity. The second is a system where universes are internally indexed by level expressions. These rules are reminiscent of Agda's, but we do not have a {\em type} of universe levels. Instead we add a new judgment $l\ \Level$ meaning that $l$ is a universe level, and $l = m$ meaning that $l$ and $m$ are equal universe levels, where level expressions are built up from variables $\alpha$ by a successor operation $l^+$ and suprema $l \vee m$. We first introduce rules for ML-style universe polymorphism, where judgments are indexed by level variables. Then we add rules for level-indexed product types $[\alpha]A$ meaning "$A$ is a type for all universe levels $\alpha$". The third system is based on Voevodsky's proposal for a system with level constraints. We also propose a fast algorithm for solving such constraints. We survey the evolution of rules for universes in type theory. In particular, we discuss the relationship between our systems and a system with a minimal super universe.
\end{abstract}

\section{Introduction}

This note records discussions between the authors concerning the appropriate setting for univalent mathematics in Martin Löf type theory.

The first published version of Martin-Löf's theory \cite{martinlof:predicative} introduces a countable sequence of universes
$$
\UU_0 : \UU_1 : \UU_2 : \cdots
$$
Before the advent of univalent foundations, one expected only the first few universes to be relevant in practical formalisations. This suggests that it might be feasible for a users of type theory to explicitly assign universe levels to their types, and whenever necessary repeat definitions when they are needed on different levels. However, the number of copies of definitions does not only grow with the level, but also with the number of type arguments in the definition of a type former. We remark that universes are more important in a predicative framework than in an impredicative one. Consider for example the formalisation of real numbers as Dedekind cuts, or domain elements as filters of formal neighbourhoods, which belong to $\UU_1$ since they are properties of elements in $\UU_0$.

To deal with this duplication problem Huet \cite{Huet87} and Harper and Pollack \cite{HarperP91} introduced {\em universe polymorphism}. However, the precise formulation and implementation of universe polymorphism has been a subject of much debate, and different proof assistants use different approaches. This is a practical problem since universe level inference can be a costly operation, sometimes more costly than the usual type-checking.

%\section{What is a univalent type theory?}

The need for a good way of dealing with universe polymorphism has increased with the advent of Voevodsky's univalent foundations, see for example \cite{VV}. This theory highlights the higher dimensional aspects of type theory, and higher universes become more important than before
Universe polymorphism has also been a common topic of discussion in the context of Voevodsky's univalent foundations. The {\em univalence axiom} states that for any two types $X,Y$ the canonical map
$$
\idtoeq_{X,Y} : (X=Y)\to (X\simeq Y)
$$
is an equivalence. Formally, the univalence axiom is an axiom (or axiom scheme) added to Martin-Löf type theory. If we work in the above-mentioned setting with a countable sequence of universes, such a universe $\UU_n$ is {\em univalent} provided for all $X,Y : \UU_n$ the canonical map $\idtoeq_{X,Y}$ is an equivalence. Let $\UA_n$ be the type expressing the univalence of $\UU_n$, and
$$
\ua_n : \UA_n
$$
for $n = 0,1,\ldots$, be a sequence of constants expressing the instances of the univalence axiom. We note that $X = Y : \UU_{n+1}$ and $X\simeq Y : \UU_n$ and hence $\UA_n$ is in $\UU_{n+1}$. If we have universe polymorphism expressed as quantification over universe levels, as in the Agda system, then we can express univalence of all universes as one typing:
$$
\ua : (l : \Level) \to \UA_l
$$
in Agda's notation.

In this note we shall present some extensions of type theory which are loosely based on Agda's level-mechanism. We will also present Voevodsky's system \cite{VV} which maintains constraints between level-variables, and an algorithm for solving those constraints.

\paragraph{Plan.} We begin by providing some historical background about the evolution of universes in type theory. In particular, we shall discuss Palmgren's next universe operator and super universe, and point out that the super universe makes it possible to define an internally quantified sequence of universes. We shall also discuss how the rules for universes are formalized in terms of operations and equations extending the generalised algebraic theory of categories with families. Furthermore, we discuss the role of universes in Martin-Löf's logical framework and how this differs from Agda's logical framework. In Section \ref{external} we state the rules for a basic version of Martin-Löf type theory with $\Pi, \Sigma, \NN$, an identity type former $\Id$, and an externally indexed sequence of universes $\UU_n, \T_n$ \`a la Tarski. We then add cumulativity rules for these universes. In Section \ref{internal} we introduce the notion of universe level, and let judgments depend not only on a context of ordinary variables, but also on a list of level variables $\alpha_1, \ldots, \alpha_k$, giving rise to a theory with level polymorphism. This is a kind of ML-polymorphism since we only quantify over global level variables. We then further extend the theory with level-indexed products of types $[\alpha]A$. In Section \ref{constraints} we present Voevodsky's proposal with constraints between level variables. We also propose a fast algorithm for solving those constraints; Voevodsky only pointed out that the solvability of the constraints is decidable, since they can be encoded in Presburger arithmetic.

\section{A brief history of universes in type theory}

\subsection{External sequences of universes}\label{palmgren}

Martin-Löf \cite{martinlof:predicative} introduced the above-mentioned version of his intuitionistic type theory with an external countable sequence of universes. In this theory the only judgment is  $\Gamma \vdash a : A$. Moreover, it has an untyped notion of conversion $a\ \conv\ a'$. There is no judgment $A\ \type$; since a type is an $A : \UU_n$ for some $n$. Universes are here \`a la Russell, that is, there is no notational distinction between an element $A : \UU_n$ and the type $A$. However, there is no rule of cumulativity ensuring that $A : \UU_m$ implies $A : \UU_n$ for $m \leq n$.

Martin-Löf \cite{martinlof:hannover} changed the judgment structure and added the judgment form $\Gamma \vdash A\ \type$
%\footnote{We should be systematic with respect to notation: shall we show all the old notations or the notations we use nowadays?} 
and replaced the untyped conversion judgments with typed equality judgments $\Gamma \vdash a = a' : A$ and $\Gamma \vdash A = A'$. There is still an external sequence of universes \`a la Russell. A cumulativity rule was also added.

Martin-Löf \cite{martinlof:padova} gave an alternative formulation of the first universe $\UU_0$ \`a la Tarski with decoding $\T_0$, such that $\T_0(a)$ is a type if $a : \UU_0$. 
%\footnote{Did he discuss two universes?}.
Palmgren \cite{palmgren:venice} then proposed two alternatives for rules for the external sequence of universes $\UU_n$ \`a la Tarski with decodings $\T_n$. 

The first version is entitled "universes as full reflection" and was only outlined for the first and the second universe. We will give a full presentation of this theory in Section \ref{external}. In this version there is a cumulativity map $\T_0^1 : \UU_0 \to \UU_1$ which is defined by recursion on the way the elements of $\UU_0$ are defined. For example, assume that $\pi_0$ and $\pi_1$ are the functions which represent the closure under $\Pi$ of $\UU_0$ and of $\UU_1$, respectively. Then one of the defining equations of $\T_0^1$ is
$$
\T_0^1\, (\pi_0\,a\, b) = \pi_1\,(\T_0^1\,a)\,(\lambda x.\T_0^1\,(b\,x))
$$
However, the right hand side of this equations is ill-typed, unless we stipulate the following judgmental equality
$$
\T_1\, (\T_0^1\, a) = \T_0\, a\ (*)
$$
Note however that this equation depends on $\T_0^1$ itself, the function we are in the process of defining! If we nevertheless allow the ill-typed equation above, it will follow that the second equation will be valid for all $a : \UU_0$, that is, it will be valid extensionally in a realizability model, for example, in the style of Allen \cite{allen}. 

In such a model each type is interpreted as a partial equivalence relation (per) on a set of untyped terms (the realizers). This per represents well-typed terms up to typed judgmental equality. Moreover, there is a per that represents well-formed types up to judgmental equality of types. The defining equations for $\T_0, \T_1,$ and $\T_0^1$ will all be valid in this model. The pers for $\UU_0$ and $\UU_1$ (together with their respective decoding maps $\T_0$ and  $\T_1$) have an informal inductive-recursive character, which will be represented as fixed points of monotone operators in set-theoretic metalanguage \cite{allen}. On this basis you can prove by induction on $\UU_0, \T_0$ that the two sides of the judgmental equality (*) are related by the per for equal well-formed types, and hence that the defining equation for $\T_0^1$ is well-typed.

We could even argue that we only need to know this equation for $\T_0^1\, a$, when defining $\T_0^1\, (\pi_0\,a\, b)$, so we could claim that this equation is known when it is needed. Would it be correct to say that this is a "definitional equality"? In one sense no, because $\T_1$ was already defined earlier, and we cannot stipulate its effect on $\T_0^1\, a$. On the other hand it seems that adding this equation as a judgmental equality does not destroy the decidability of the system.

Palmgren's second version of the external sequence is entitled "universes as uniform constructions". Here the map $\T_0^1 : \UU_0 \to \UU_1$ is a constructor for the second universe $\UU_1$. However, this means that we do not have full reflection: $\UU_1$ contains canonical elements which have no counterpart as canonical types.

\subsection{Internal sequences of universes and the super universe}

Palmgren \cite{palmgren:venice} went on to internalize the construction of the infinite sequence of universes  \`a la Tarski. To this end he introduced the {\em next-universe operator}, which given a family of types $U, T$, constructs a new family of types $U^+, T^+$, such that $ \UU_{n+1} = \UU_n^+$ and $\T_{n+1} = \T_n^+$.

Furthermore, Palmgren introduced a {\em super universe} (\`a la Tarski), which is a type containing a code for the first universe and is closed under the next-universe operator as well as under all the usual small type formers. In this theory we can define an internal sequence of universes $n : \NN \vdash \UU_n$, and also express univalence of this sequence as one typing:
$$
\ua : \Pi_{n : \N}\, \UA_n
$$
using the ordinary $\Pi$-type former of type theory.

In fact, we point out that the notion of "universe" is rather general - any inductive-recursive definition can be viewed as a universe closed under some given operations. Thus for univalence, it suffices to introduce a {\em minimal super universe} with $\N$ as the type of codes, and with decoding $\Tsuper$,
such that $\Tsuper\,0$ is the empty universe and $\Tsuper\,(n + 1)$ is the next universe above $\Tsuper\,n$, so that the first universe $\UU_0$ is represented by $\Tsuper\,1$, the next universe above the empty universe. Thus all we need to add to Martin-Löf type theory without universes is (i) the empty universe, (ii) the next-universe operator, (iii) the minimal super universe.

%We remark that in type theory with Setzer's {\em Mahlo universe} we get Palmgren's super universe as a special case.

\subsection{The generalised algebraic theory of type theory with universes}

Models of type theory can be expressed as categories with families (cwfs) with extra structure for modelling the rules for type formers.  A key feature of cwfs is that they can be expressed as models of a generalised algebraic theory in the sense of Cartmell \cite{cartmell:apal}, and also that the extra structure for type formers can be expressed by adding more operations and equations to the generalised algebraic theory of cwfs. When we add new rules to type theory, it is desirable that the corresponding extra structure on  models also can be expressed in terms of operations and equations to the generalised algebraic theory of cwfs. We should therefore ask ourselves which extra structure is needed for modelling universe hierarchies.

For example, we can formulate the new operations and equations for universes that need to be added to the generalised algebraic theory of cwfs. For example, $\UU_0,\T_0,\UU_1, \T_1,$ and $\T_0^1$ can be added as new operations, and we can add the defining equations for $\T_0, \T_1,\T_0^1$, including the equation
$
\T_1\, (\T_0^1\, a) = \T_0\, a
$
which we discussed above.
For example, $\Pi$-formation is written 
\begin{eqnarray*}
\Pi&: &(\Gamma : \Ctx) \to (A : \Ty(\Gamma; B : \Ty(\Gamma.A)) \to\Ty(\Gamma)
\end{eqnarray*}
where $\Gamma.A$ denotes the extension of the context $\Gamma$ with a new type $A$ depending on $\Gamma$ (using variable free notation). Moreover, the formation rules for the first universe become
\begin{eqnarray*}
\UU_0 &: &(\Gamma : \Ctx) \to \Ty(\Gamma)\\
\T_0 &: &(\Gamma : \Ctx ; a : \Tm(\Gamma,\UU_0(\Gamma)))\to \Ty(\Gamma)
%\\
%\UU_1 &: &(\Gamma : \Ctx) \to \Ty(\Gamma)\\
%\T_1 &: &(\Gamma : \Ctx ; A : \Tm(\Gamma,\UU_1(\Gamma)))\to \Ty(\Gamma)\\
%\T_{01} &:&(\Gamma : \Ctx) \to \UU_0(\Gamma) \to \UU_1(\Gamma)
\end{eqnarray*}
and its closure under $\Pi$ is represented by the following introduction rule:
\begin{eqnarray*}
\pi_0&: &(\Gamma : \Ctx) \to (a : \Tm(\Gamma,\UU_0(\Gamma)); b : \Tm(\Gamma.\T_0(\Gamma,a),\UU_0(\Gamma))) \to\Tm(\Gamma,\UU_0(\Gamma))
\end{eqnarray*}
with decoding
\begin{eqnarray*}
\T_0(\Gamma,\pi_0(\Gamma,a,b)) &=& \Pi(\Gamma,\T_0(\Gamma,a), \T_0(\Gamma.\T_0(\Gamma,a),b))
\end{eqnarray*}

\subsection{Universes in Martin-Löf's logical framework}

The rules for the various universes \`a la Tarski that we discussed above can also be formulated using Martin-Löf's logical framework \cite{Martinlof86,NordstromPS90}. This framework has $\Pi$-types (written $(x : A)B$ by Martin-Löf and abbreviated $(A)B$ when $B$ does not depend on $x$.) and a type $\Set$ which is a "universe" with a special role. We will here use the formulation \`a la Tarski of $\Set$ with decoding $\El$, but there is also a formulation \`a la Russell which often used in practice. The formation, introduction, and elimination rules of type theory are formulated as typings of constants $c : A$, and the equality rules are formulated as equations $a = a' : A$. The idea is that $A : \Set$ in the logical framework version represents $A$ {\em type} in the earlier formulations of type theory, and the {\em typing} $f : (x : A)B$ represents the {\em rule} that if $a : A$ then $f\,a : B$.

For example, the formation rule for $\Pi$-sets (as opposed to types) is represented by the typing
\begin{eqnarray*}
\Pi &:& (A:\Set)((\El\,A)\,\Set)\,\Set
\end{eqnarray*}
and the formation rules for first universe (\`a la Tarski) are represented by the typings
\begin{eqnarray*}
\UU_0 &: &\Set\\
\T_0 &:& (\El\,\UU_0)\,\Set
\end{eqnarray*}
The first typing represents the rule that $\UU_0$ is a type in the original version of type theory, and the second typing represents the rule that if $a : \UU_0$, then $\T_0\,a$ is a type. We also have constants for the introduction rules for $\UU_0$ and equality rules for their decodings. For example, closure under $\pi$ is expressed by
\begin{eqnarray*}
\pi_0 &:& (a:\El\, \UU_0)(\El\, (\T_0\, a))(\El\, \UU_0)\,\El\, \UU_0
\end{eqnarray*}
with decoding
\begin{eqnarray*}
\T_0\, (\pi_0\, a\, b) &=& \Pi (\T_0\, a) ((x)\,\T_0\, (b\, x))
\end{eqnarray*}
In this system we have three levels of products: $\pi\,a\,b : \UU_0$, $\Pi\,A\,B : \Set$ and the type $(x : A)B$.
%
%
%There is no problem adding further constants and equations for the next-universe operator and the minimal super universe to the logical framework.
%\begin{eqnarray*}
%\UU_n &: &\Set\\
%\T_n &:& \El\,\UU_n \to \Set
%\end{eqnarray*}
%Closure under $\pi$ is expressed by
%\begin{eqnarray*}
%\pi_n &:& (X:\El\, \UU_n) \to (\El\, (\T_n\, X) \to \El\, \UU_n) \to \El\, \UU_n \\
%\T_n\, (\pi X F) &=& \Pi (\T_n\, X) (\ (x: \El\, (\T_n\, X)) \T_n\, (F x))
%\end{eqnarray*}
%
% Also we have Pi sets with a new constructor Lambda for functions

\section{Universes in Agda}

So far we have discussed the formulation of the univalence axiom in what might be called "standard" versions of Martin-Löf type theory, where the \`a la Tarski rules for universes and super universes follow the general pattern of inductive-recursive definitions in type theory. (Recall however again that the equation
$
\T_0^1\, (\pi_0\,a\, b) = \pi_1\,(\T_0^1\,a)\,(\lambda x.\T_0^1\,(b\,x))
$
which is a function defined by universe elimination on $\UU_0$ does not type-check unless we stipulate $\T_1\, (\T_0^1\, a) = \T_0\, a$.)


The proof assistant Agda is loosely based on Martin-Löf's logical framework, but with several modifications which are relevant to our discussion. Firstly, it is based on a "logical framework" which is different from Martin-Löf's. It has the following features:
\begin{itemize}
\item It has a sequence of universes  $$\Set_0 : \Set_1 : \Set_2 : \cdots$$  \`a la Russell.
\item It has built in dependent function types written $\Gamma \vdash (x : A)\to B : \Set_n$ for $\Gamma \vdash A : \Set_n$ and $\Gamma , x : A \vdash B : \Set_n$
\item It has a special type $\Level$ of universe levels, which makes it possible to define {\em universe polymorphic} types and terms.
\end{itemize}
This is a logical framework in the sense that we can add new concepts by adding new constants with their types $c : A$, and also add new equations $a = a' : A$ in the same way as in Martin-Löf's logical framework. For example, we can define universes \`a la Tarski in a similar way as we showed above for Martin-Löf's logical framework:
\begin{eqnarray*}
\UU_0 &: &\Set_0\\
\T_0 &:& \UU_0 \to \Set_0
\end{eqnarray*}
However, most Agda users only make use of the built in universes $\Set_n$, and do not introduce such "internal" universes as $\UU_n, \T_n$. Moreover, most Agda users only make use of the built in function types $(x : A)\to B : \Set_n$ and don't introduce "user defined data types" such as
\begin{eqnarray*}
\Pi_0 &:& (A:\Set_0) \to (A \to \Set_0) \to \Set_0
\end{eqnarray*}
for representing $\Pi$-types as we did in Martin-Löf's logical framework. As a consequence it is more appropriate to think of Agda's sequence of universes as analogous to the sequence of universes  \`a la Russell $ \UU_0 : \UU_1 : \UU_2 : \cdots$ in the early versions of Martin-Löf type theory. However, since Agda has a type $\Level$ of levels, we can define a function $i : \N \to \Level$, and hence the family $n : \N \vdash \Set_{i\, n}$ analogous to the family $n : \N \vdash \Tsuper\,(n + 1)$ in type theory with a minimal super universe. However, Agda does not have a type analogous to $\Usuper$, only a "kind" $\Set_\omega$ which is not a type. See the Agda wiki for more explanation.

In the following section we shall give the rules for a version of type theory with a system of universes with level quantification. Although it is similar to Agda's system, it differs in important respects, since we shall neither introduce a {\em type} of levels nor a kind $\Set_\omega$.

\section{A type theory with an external sequence of universes}\label{external}

As already mentioned the rules for the minimal super universe follow the pattern of inductive-recursive definitions, and is a natural candidate for a clean formulation of a type theory which allows quantification over countably many universe levels. Thus the universe levels are members of the type $\N$, and the operation $l \vee m$ is the maximum operation on $\N$, which can be defined by induction on $l$ or $m$. Unfortunately, we have to make a choice between $l$ and $m$ and hence not all equations of level arithmetic (making levels a sup-semi-lattice) will be definitional.

For this reason, we will here propose an alternative formulation, where we do not have a {\em type} of levels. Instead we have new judgments $l\ \Level$, meaning that $l$ is a level expression, and $l = m$ meaning that $l$ and $m$ are definitionally equal levels . We have a maximum operation $\vee$ on levels such that levels become a sup-semilattice up to definitional equality. We also remark that the proof theoretic strength of this alternative system is less than the system with a minimal super universe.

\subsection*{Rules for a basic type theory}

We begin by listing some rules for a basic type theory with $\Pi, \Sigma, \N,$ and $\Id$, such as the rules of context formation and assumption:
$$
\frac{\Gamma\vdash A}{\Gamma,x:A\vdash}~~~~~~\frac{}{()\vdash}~~~~~~~
\frac{\Gamma\vdash}{\Gamma\vdash x:A}~(x\!:\! A~in~\Gamma)
$$
The judgment $\Gamma\vdash A$ expresses that $A$ is a type in context $\Gamma$.
We may write it $A~\type~(\Gamma)$ and may omit the global context $\Gamma$.
For instance, the rules
$$
%\frac{\Gamma,x:A\vdash B}{\Gamma\vdash \Pi (x:A) B}~~~~~~~~~
\frac{\Gamma\vdash A~~~~~~\Gamma,x:A\vdash B}{\Gamma\vdash \Pi (x:A) B}~~~~~~~~~
\frac{\Gamma,x:A\vdash b:B}{\Gamma\vdash \lambda (x:A) c:\Pi (x:A) B}~~~~~~~~
\frac{\Gamma\vdash c:\Pi (x:A) B~~~~~~\Gamma\vdash a:A}
     {\Gamma\vdash c~a:B(a/x)}
$$
can be written
$$
%\frac{\Gamma,x:A\vdash B}{\Gamma\vdash \Pi (x:A) B}~~~~~~~~~
\frac{A~\type~~~~~~B~\type~(x:A)}{\Pi (x:A) B~\type}~~~~~~~~~
\frac{b:B~(x:A)}{\lambda (x:A) b:\Pi (x:A) B}~~~~~~~~
\frac{c:\Pi (x:A) B~~~~~~a:A}
     {c~a:B(a/x)}
$$

We also have
$$
%\frac{\Gamma,x:A\vdash B}{\Gamma\vdash \Pi (x:A) B}~~~~~~~~~
\frac{A~\type~~~~~~B~\type~(x:A)}{\Sigma (x:A) B~\type}~~~~~~~~~
\frac{a:A~~~~~~b:B(a/x)}{(a,b):\Sigma (x:A) B}~~~~~~~~
\frac{c:\Sigma (x:A) B}{c.1:A}~~~~~~~
\frac{c:\Sigma (x:A) B}{c.2:B(c.1/x)}
$$

We write $\conv$ for definitional equality (or conversion). The main conversion rules are
$$
\frac{ a:A~~~~~~ A~ \conv~ B}{ a:B}~~~~~~~~~
\frac{ a ~\conv~a':A~~~~~~ A  ~\conv~ B}{ a ~\conv~a':B}
$$
$$
\frac{b:B~(x:A)~~~~~~~~ a:A}{ (\lambda (x:A)b)~a  ~\conv~ b(a/x):B(a/x)}
~~~~~~~
\frac{f~x = g~x:B~(x:A)}{ f = g : \Pi (x:A)B}
$$
$$
\frac{ a:A~~~~~~ b:B(a/x)}{ (a,b).1  ~\conv~ a:A}
~~~~~~~
\frac{ a:A~~~~~~ b:B(a/x)}{ (a,b).2  ~\conv~ b:B(a/x)}~~~~~~
\frac{ a.1 = a'.1:A~~~~~~~ a.2 = a'.2:B(t.1/x)}{ a = a' : \Sigma (x:A)B}
$$

We can introduce data types: the type of natural numbers $\NN$ has
constructors $\ZERO:\NN$ and $\SUCC:\NN\rightarrow\NN$ and elimination rules
$$
\frac{P~\type~(x:\NN)~~~~a:P(\ZERO/x)~~~~~g:\Pi (x:\NN)(P\rightarrow P(\SUCC~x/x))}{\natrec(a,g):\Pi (x:\NN)P}
$$
with conversion rules $\natrec(a,g)~\ZERO = a$ and $\natrec(a,g)~(\SUCC~x) = g~x~(\natrec(a,g)~x)$.
%\footnote{change to version with $\natrec(a,g,n)$?}

We also have a type $\Id~A~a_0~a_1$ for $a_0:A$ and $a_1:A$ with $\refl~a:\Id~A~a~a$
and the elimination rule
$$\frac{a:A~~~~~C~\type~(x:A,p:\Id~A~a~x)~~~~~d:C(a/x,\refl~a/p)}{\JJ (a,d):\Pi (x:A)(p:\Id~A~a~x)C}$$
with the conversion rule $\JJ(a,d)~a~(\refl~a) = d$.

\subsection*{Rules for an external sequence of universes}

We will now present a complete set of rules for "universes as full reflections" in the style of the rules in Section \ref{palmgren}. We first present a version without cumulativity.
$$
\UU_n~\type~~~~~~
\frac{A:\UU_{n}}{\T_{n}(A)~\type}
$$
$$
\frac{A:\UU_{n}~~~~~~B:\T_{n}(A)\rightarrow \UU_{m}}
     {\Pi^{n,m} A B:\UU_{n\vee m}}~~~~~~~~~
\frac{A:\UU_{n}~~~~~~B:\T_{n}(A)\rightarrow \UU_{m}}
     {\Sigma^{n,m} A B:\UU_{n\vee m}}~~~~~~~~~
$$
where $n$ and $m$ are external natural numbers, and $n \vee m$ is the maximum of $n$ and $m$. This means for example, that $\UU_n~\type$ is a {\em schema}, yielding one rule for each $n$.
The conversion rules are
$$
\T_{n\vee m}~(\Pi^{n,m} A B) = \Pi (x:\T_{n}(A)) \T_{m}(B~x)~~~~~~~
\T_{n\vee m}~(\Sigma^{n,m} A B) = \Sigma (x:\T_{n}(A)) \T_{m}(B~x)~~~~~~~
$$
Furthermore we have $$\NN^{n}:\UU_{n}$$
$$\T_{n}(\NN^{n}) = \NN$$
and
$$
\frac{A:\UU_n~~~~~~a_0:\T_n(A)~~~~~~a_1:\T_n(A)}
{\Id^n~A~a_0~a_1:\UU_n}
$$
$$\T_n(\Id^n~A~a_0~a_1) = \Id~\T_n(A)~a_0~a_1$$
and a code for the previous universe
$${\UU^{n}}:\UU_{n + 1}$$
$$\T_{n + 1}({\UU^{n}}) = \UU_{n}$$

Note that $\UU_p, \T_p$ are given by separate inductive-recursive definition for each $p$. There is one introduction rule for each $\Pi^{n,m}$ and $\Sigma^{n,m}$ such that $p = m \vee n$ and introduction rules for $\NN^p, \Id^p$, and also for $\UU^{p-1}$ provided $p \geq 1$.
%\subsection*{Rules for cumulativity}
%
%With cumulativity, we introduce an operation
%$$
%\frac{A:\UU_{n}}
%{\T_{n}^{m}(A):\UU_{m}}
%n\leqslant m
%$$
%We can also formulate the side condition as an equaton $m = n \vee m$.
%We require
%\begin{eqnarray*}
%\T_m(\T_{n}^{m}(A)) &=& \T_{n}(A)
%\end{eqnarray*}
%and
%\begin{eqnarray*}
%T_{n}^{m}(\NN^{n}) &=& \NN^{m}
%\end{eqnarray*}
%
%We add $$
%T_{n}^m(A) = A
%$$
%if $n = m$
%and $$T_{m}^n\T_{n}^m = T_n^n$$ if $n\leqslant m\leqslant n$.
%
%We can then simplify the product and sum rules to
%$$
%\frac{A:\UU_{n}~~~~~~B:\T_{n}(A)\rightarrow \UU_{n}}
%     {\Pi^{n} A B:\UU_{n}}~~~~~~~~~
%\frac{A:\UU_{n}~~~~~~B:\T_{n}(A)\rightarrow \UU_{n}}
%     {\Sigma^{n} A B:\UU_{n}}~~~~~~~~~
%$$
%with conversion rules
%$$
%\T_{n}~(\Pi^{n} A B) = \Pi (x:\T_{n}(A)) \T_{n}(B~x)~~~~~~~
%\T_{n}~(\Sigma^{n} A B) = \Sigma (x:\T_{n}(A)) \T_{n}(B~x)~~~~~~~
%$$
%and
%$$
%\T_{n}^{m}~(\Pi^{n} A B) = \Pi^{m} \T_{n}^{m}(A) (\lambda (x:\T_{n}(A))\T_{n}^{m}(B~x))~~~~~~
%\T_{n}^{m}~(\Sigma^{n} A B) = \Sigma^{m} \T_{n}^{m}(A) (\lambda (x:\T_{n}(A))\T_{n}^{m}(B~x))~~~~~~
%$$
%
\subsection*{Rules for cumulativity}

We define an operation which injects elements of a lower universe into a higher universe:
$$
\frac{A:\UU_{n}}
{\T_{n}^{m}(A):\UU_{m}}
n < m
$$
We can also formulate the side condition as an equation $m = n^+ \vee m$.
We postulate the conversion (cf the discussion of Palmgren's rules for full reflection in Section \ref{palmgren}):
\begin{eqnarray*}
\T_m(\T_{n}^{m}(A)) &=& \T_{n}(A)
\end{eqnarray*}
and the decoding conversion
%\footnote{We should check our use of "conversion" vs "definitional equality" throughout the document.}
\begin{eqnarray*}
\T_{n}^{m}(\NN^{n}) &=& \NN^{m}
\end{eqnarray*}
In the presence of cumulativity we can simplify the product and sum rules to
$$
\frac{A:\UU_{n}~~~~~~B:\T_{n}(A)\rightarrow \UU_{n}}
     {\Pi^{n} A B:\UU_{n}}~~~~~~~~~
\frac{A:\UU_{n}~~~~~~B:\T_{n}(A)\rightarrow \UU_{n}}
     {\Sigma^{n} A B:\UU_{n}}~~~~~~~~~
$$
with conversion rules
$$
\T_{n}~(\Pi^{n} A B) = \Pi (x:\T_{n}(A)) \T_{n}(B~x)~~~~~~~
\T_{n}~(\Sigma^{n} A B) = \Sigma (x:\T_{n}(A)) \T_{n}(B~x)~~~~~~~
$$
and
$$
\T_{n}^{m}~(\Pi^{n} A B) = \Pi^{m} \T_{n}^{m}(A) (\lambda (x:\T_{n}(A))\T_{n}^{m}(B~x))~~~~~~
\T_{n}^{m}~(\Sigma^{n} A B) = \Sigma^{m} \T_{n}^{m}(A) (\lambda (x:\T_{n}(A))\T_{n}^{m}(B~x))~~~~~~
$$

The problem with this approach is that we have to {\em duplicate} definitions that follow
the same pattern. For instance, we have the identity function $\lambda (X:\UU_n)(x:\T_n(X))x$
of type $\Pi (X:\UU_n)(\T_n(X)\rightarrow \T_n(X))$ that can be defined for $n = 0,1,\dots$
The systems in the next sections address this issue.

\section{A type theory with universe levels and polymorphism }\label{internal}

We introduce {\em universe level} expressions: we write $\alpha,\beta,\dots$
for {\em level variables}, and $l,m,\dots$ for {\em level expressions} which are built from level variables
by suprema $l \vee m$ and the next level operation $l^+$.
Level expressions form a sup semilattice $l\vee m$
with a next level operation $l^+$ such that $l \vee l^+ = l^+$
and $(l\vee m)^+ = l^+\vee m^+$. (We don't seem to need a $0$ element.)
%As expressed in \cite{VV}, this is essentially a tropical (max-plus)
%semiring, except that we don't actually seem to need a $0$ element.

We have a new context extension operation adding a fresh level variable $\Gamma,\alpha~\Level$
to a given context.
$$
\frac{}{\alpha~\Level~(\Gamma)}(\alpha~in~\Gamma)~~~~~~
\frac{l~\Level~~~~~m~\Level}{l\vee m~\Level}~~~~~~
\frac{l~\Level}{l^+~\Level}~~~~~~
$$
We also have rules that judgments are invariant under level equality. For example,
$$
\frac{a(l/\alpha) : A(l/\alpha)\ \ \ l = m}
{a(m/\alpha) : A(m/\alpha)}
$$
We can now replace the rule schemata for externally indexed universes by corresponding rules which are internally indexed by level expressions.
$$
\frac{l~\Level}{\UU_{l}~\type}~~~~~~
\frac{A:\UU_{l}}{\T_{l}(A)~\type}~~~~~~
$$
$$
\frac{A:\UU_{l}~~~~~~B:\T_{l}(A)\rightarrow \UU_{m}}
     {\Pi^{l,m} A B:\UU_{l\vee m}}~~~~~~~~~
\frac{A:\UU_{l}~~~~~~B:\T_{l}(A)\rightarrow \UU_{m}}
     {\Sigma^{l,m} A B:\UU_{l\vee m}}~~~~~~~~~
$$
with conversion rules
$$
\T_{l\vee m}~(\Pi^{l,m} A B) = \Pi (x:\T_{l}(A)) \T_{m}(B~x)~~~~~~~
\T_{l\vee m}~(\Sigma^{l,m} A B) = \Sigma (x:\T_{l}(A)) \T_{m}(B~x)~~~~~~~
$$
Furthermore we have $$\NN^{l}:\UU_{l}$$
$$\T_{l}(\NN^{l}) = \NN$$
and
$$
\frac{A:\UU_l~~~~~~a_0:\T_l(A)~~~~~~a_1:\T_l(A)}
{\Id^l~A~a_0~a_1:\UU_l}
$$
$$\T_l(\Id^l~A~a_0~a_1) = \Id~\T_l(A)~a_0~a_1$$
and a code for the previous universe
$${\UU^{l}}:\UU_{l + 1}$$
$$\T_{l + 1}({\UU^{l}}) = \UU_{l}$$
Note that all the rules are completely analogous to the rules for externally indexed universes with external numbers replaced by internal levels. In this way we avoid having to duplicate definitions for different universe levels.
%
%\medskip
%
%We also have ${\UU^{l}}:\UU_{l^+}$ with
%$\T_{l^+}({\UU^{l}}) = \UU_{l}$.
%
%\medskip
%
%For data types, we introduce $\NN^{l}:\UU_{l}$ with the conversion rule
%$\T_{l}(\NN^{l}) = \NN$.
%
%We have $\Id^l~A~a_0~a_1:\UU_l$ for $A:\UU_l$ and $a_0:\T_l(A)$ and $a_1:\T_l(A)$
%with $\T_l(\Id^l~A~a_0~a_1) = \Id~\T_l(A)~a_0~a_1$.
%
%\medskip
%

The following rule should be admissible:
we can derive $A = B : \UU_l$ from $\T_l(A) = \T_l(B)$.
 It expresses that $\T_l$ is an embedding from the collection of elements of $\UU_l$
 to the collection of types.
 (Voevodsky \cite[Rule 20 on p. 17]{VV} adds this as an internal rule, but then the system is not
 generalized algebraic anymore.)

It should be the case that if $a :\NN$ in a context with only level variables
then $a$ is convertible to a numeral.

In such a system we can state that all universes are univalent as a type and the
fact that if all universes are univalent then they all satisfy function extensionality.

We can also add rules for cumulativity which are completely analogous to those for the internally indexed universes.

\paragraph{Interpreting the level-indexed system in the system with externally indexed universes.}

A judgment in the level-indexed system can be interpreted in the the externally indexed system relative to an assignment $\rho$ of external natural numbers to level variables. We simply replace each level expression in the judgment by the corresponding natural number obtained by letting $l^+\,\rho = l\,\rho+1$ and $(l \vee m)\,\rho = \max(l\,\rho,m\,\rho)$.

%
%
%\subsection*{Cumulativity}
%
%We introduce an operation $\T_{l}^{m}(A):\UU_{m}$ if $A:\UU_{l}$
%and $l\leqslant m$ (i.e. $m = l\vee m$).
%
%We require $\T_{m}(\T_{l}^{m}(A)) = \T_{l}(A)$
%and $\T_{l}^{m}(\NN^{l}) = \NN^{m}$.
%
%We add $\T_{l}^m(A) = A$ if $l = m$
%and $\T_{m}^n\T_{l}^m = \T_l^n$ if $l\leqslant m\leqslant n$.
%
%We can then simplify the product and sum rules to
%
%$$
%\frac{A:\UU_{l}~~~~~~B:\T_{l}(A)\rightarrow \UU_{l}}
%     {\Pi^{l} A B:\UU_{l}}~~~~~~~~~
%\frac{A:\UU_{l}~~~~~~B:\T_{l}(A)\rightarrow \UU_{l}}
%     {\Sigma^{l} A B:\UU_{l}}~~~~~~~~~
%$$
%with conversion rules
%$$
%\T_{l}~(\Pi^{l} A B) = \Pi (x:\T_{l}(A)) \T_{l}(B~x)~~~~~~~
%\T_{l}~(\Sigma^{l} A B) = \Sigma (x:\T_{l}(A)) \T_{l}(B~x)~~~~~~~
%$$
%and
%$$
%\T_{l}^{m}~(\Pi^{l} A B) = \Pi^{m} \T_{l}^{m}(A) (\lambda (x:\T_{l}(A))\T_{l}^{m}(B~x))~~~~~~
%\T_{l}^{m}~(\Sigma^{l} A B) = \Sigma^{m} \T_{l}^{m}(A) (\lambda (x:\T_{l}(A))\T_{l}^{m}(B~x))~~~~~~
%$$

\subsection*{Rules for level-indexed products}

In Agda $\Level$ is a type, and it is thus possible to form level-indexed products of types. In our system $\Level$ is not a type, but if we want to be able to form level-indexed products we can extend the system with the following rules:
$$
\frac{A~\type~(\alpha~\Level)}{[\alpha]A~\type}~~~~~~~
\frac{t:[\alpha]A~~~~~l~\Level}
     {t~l:A(l/\alpha)}~~~~~~~~~
\frac{u:A~(\alpha~\Level)}{\lam{\alpha}{u}: [\alpha]A}~~~~~
\frac{t~\alpha = u~\alpha:A~(\alpha~\Level)}{t = u:[\alpha]A}
$$
with conversion rule $(\lam{\alpha}{u})~l = u(l/\alpha)$.

An example that uses level-indexed products is the following type which  expresses the theorem that univalence for universes of arbitrary level implies function extensionality for functions between universes of arbitrary levels.
$$
([\alpha]\mathsf{IsUnivalent}\, \UU_\alpha)
\to [\beta][\gamma] \mathsf{FunExt}\, \UU_\beta\, \UU_\gamma
$$   
               
We note that all functions in $[\alpha]\NN$ in our system
should be constant. 

\paragraph{Interpreting the system with levels into extensional type theory with a super universe.} We can interpret the theory with rules for level-indexed products in extensional type theory with a (minimal) super universe. Levels will be interpreted by internal natural numbers $n : \NN$, and level-indexed products $[\alpha]A$ will be interpreted by ordinary indexed products $\Pi_{n : \NN}A$. Level application and level abstraction will be interpreted as ordinary application and abstraction.

Note that in intensional type theory, we will not be able to justify all the laws for level expressions as definitional equalities.

\section{A system with level constraints}\label{constraints}

To motivate why it may be useful to introduce the notion of judgment relative to a list of constraints on universe levels, consider the following type in a system without cumulativity:
%[[The type constructor ``$\simeq$'' should be replaced by the identity type for this to work. I am not sure which notation for the identity type we want to use to formulate this example.]]
%$$
%    (A : \UU_l) \to (B : \UU_m) \to A \times B \simeq B \times A
%$$
%Here we get the constraint is that $l \vee m = m \vee l$, which holds for arbitrary levels $l, m$.
%
%Now  consider the theorem
$$
    (A : \UU_l) \to (B : \UU_m) \to (C : \UU_n) 
    \to \Id\,\UU_{l \vee m}\, (A\times^{l \vee m} B)\,(C \times^{n \vee l} A)
    \to \Id\,\UU_{m \vee l} \, (B\times^{m \vee l} A)\,(C \times^{n \vee l} A)
%    \to A \times B =_\delta C \times A \to B \times A =_\epsilon C \times A
$$
It is well-formed provided $l \vee m = n \vee l$ and $m \vee l = n \vee l$. Thus are three maximally general solutions: 
$$
    (A : \UU_\alpha) \to (B : \UU_\beta) \to (C : \UU_{\alpha \vee \beta}) 
    \to \Id\,\UU_{\alpha \vee \beta}\, (A\times^{\alpha \vee \beta} B)\,(C \times^{\alpha \vee \beta} A)
    \to \Id\,\UU_{\alpha \vee \beta}\, (B\times^{\alpha \vee \beta} A)\,(C \times^{\alpha \vee \beta} A)
$$
$$
    (A : \UU_\alpha) \to (B : \UU_{\gamma \vee \alpha}) \to (C : \UU_{\gamma}) 
    \to \Id\,\UU_{\gamma \vee \alpha}\, (A\times^{\gamma \vee \alpha} B)\,(C \times^{\gamma \vee \alpha} A)
    \to \Id\,\UU_{\gamma \vee \alpha}\, (B\times^{\gamma \vee \alpha} A)\,(C \times^{\gamma \vee \alpha} A)
$$
$$
    (A : \UU_{\beta \vee \gamma}) \to (B : \UU_{\beta}) \to (C : \UU_{\gamma}) 
    \to \Id\,\UU_{\beta \vee \gamma}\, (A\times^{\beta \vee \gamma} B)\,(C \times^{\beta \vee \gamma} A)
    \to \Id\,\UU_{\beta \vee \gamma}\, (B\times^{\beta \vee \gamma} A)\,(C \times^{\beta \vee \gamma} A)
$$
(Note the similarity with the Gustave function in stable domain theory.)
In a system with level constraints, we could instead derive the type
$$
    (A : \UU_\alpha) \to (B : \UU_\beta) \to (C : \UU_\gamma) 
    \to \Id\,\UU_{\alpha \vee \beta}\, (A\times B)\,(C \times A)
    \to \Id\,\UU_{\alpha \vee \beta}\, (B\times A)\,(C \times A)
$$
which is valid under the constraints
$
\alpha \vee \beta = \gamma \vee \alpha
$
and 
$
\beta \vee \alpha = \gamma \vee \alpha.
$

\subsection{Rules for level constraints}

We now try to describe Voevodsky's approach \cite{VV} using our notation.

We introduce a further judgement for {\em constraints}. A constraint is
an equations $l = m$, where $l$ and $m$ are level expression.
%Thus we have
%$$
%\frac{l_1~m_1~\dots~l_k~m_k~\Level}{l_1 = m_1,\dots,l_k = m_k~\Constraint}
%$$
We write $l\leqslant m$ for the constraint $l\vee m = m$.

We then have a new context extension $\Gamma,\psi$ if $\psi$ is a finite set of constraints in $\Gamma$.

Finally we have the judgement $\psi~(\Gamma)$ which expresses that the constraint set $\psi$
holds in $\Gamma$. For instance we have $\alpha^+\leqslant\beta^+~(\alpha\leqslant\beta)$.

In the system with constraints, we have judgements such as
$$
T_{\alpha^+}^{\beta}(\UU^{\alpha}):\UU_{\beta}~(\alpha~\beta~\Level,\alpha^+\leqslant\beta)
$$
We introduce a new product operation
$$
\frac{t:A~(\psi)}{t:[\psi]A}
$$
with the elimination rule
$$
\frac{t:[\psi]A~~~~~~\psi}{t:A}
$$
Intuitively, we can use a term of type $[\psi]A$ only if the all constraints in $\psi$ hold.

\subsection{An algorithm for deciding the solvability of constraints}

We shall now devise an algorithm for deciding whether a finite constraint set $\psi$ is solvable, that is, whether there is an assignment $\rho : \Level \to \mathbb{N}$, such that for all equations $l = m \in \psi$, we have $l\rho = m\rho$, provided we interpret $\_^+$ as the successor operation and $\vee$ as the maximum operation on $\mathbb{N}$. An assignment $M$ which satisfies all constraints in $\psi$ is called a model of $\psi$ written $M \models \psi$.

We will apply the methods in \cite{BNR08} to decide
the solvability of a set of constraints $\psi$ in polynomial time.
Here polynomial means polynomial in the number $\mu(\psi)$ of occurrences of
variables and operations $\_^+$ and $\vee$ in  $\psi$. 

%Let $ \psi$ be a finite set of constraints of the form $l=m$ as in the previous section.
%The \emph{level expressions} $l,m$ have the following abstract syntax:
%\[
%l,m,\ldots ::= {\alpha,\beta,\ldots} \mid {l^+} \mid {l\vee m}
%\]

Solving  $\psi$ can be reduced in polynomial time to solving a set  $\psi'$ of
equations of one of the two forms $\alpha\vee\beta = \gamma$
and $\delta = \epsilon^+$. Such forms are called \emph{reduced forms}.

\begin{lemma}\label{lem:reduced-form}
For every finite set  $\psi$ of constraints, there is a set  $\psi'$ of
constraints in reduced form such that  $\psi$ is solvable if and only if  $\psi'$
is solvable. Furthermore,  $\psi'$ contains precisely as many symbols $\_^+$ as  $\psi$ does,
and $\mu(\psi')\leq 2\mu(\psi)$.
\end{lemma}

\begin{proof}
We first assign to each $l$ a fresh variable $v(l)$ and then, by induction on $l$,
a set $ \psi(l)$ of constraints in reduced form such that $ \psi(l)\models l = v(l)$.

In the base case of a level variable $\alpha$ we take $v(\alpha)=\alpha$ and let $ \psi(\alpha)$ be empty. In one step case we again let $v(l^+)$ a fresh variable,
and $ \psi(l^+) =  \psi(l) \cup \set{v(l)^+ =v(l^+)}$.
In the other step case we let again $v(l\vee m)$ be a fresh variable,
and $ \psi(l\vee m) =  \psi(l) \cup  \psi(m) \cup \set{v(l)\vee v(m) =v(l\vee m)}$.
By induction we get $ \psi(l)\models l = v(l)$, plus the following two facts.
First, $ \psi(l)$ contains precisely as many symbols $\_^+$ as $l$ does,
and similarly for symbols $\vee$.
(Occurrences of such symbols in names of fresh variables do not count.)
Secondly, every assignment of variables occurring in $l$ can be extended to an
assignment validating $\psi(l)$.

Now consider a constraint $l=m$. Constraints of the form $l=l$ can
simply be removed. If $l$ and $m$ are distinct variables,
then we eliminate one of them by substitution. Otherwise,
we replace $l=m$ by $ \psi(l)\cup  \psi(m)\cup \set{v(l)=v(m)}$.
Doing this for all constraints in  $\psi$
leaves us with a set of constraints that are either in
reduced form, or of the form $v(l)=v(m)$ for distinct fresh variables.
The latter are easily removed by substitution. Let  $\psi'$ be the resulting set
of constraints, which are all in reduced form. By the results on $ \psi(l)$
and $v(l)$ from the previous paragraph, the set  $\psi$ is solvable if
and only if  $\psi'$ is solvable.

During the reduction internal nodes in the parse trees of level expressions get labelled with fresh variables and hence the $\mu$-value increases. However,  $\mu(\psi')\leq 2\mu(\psi)$ and the whole transformation, including the
elimination of variables, can certainly be done in quadratic time
(and probably better).
\end{proof}

From now on we assume that constraints are in reduced form.
Any set  $\psi$ of such constraints can be split as $ \psi= \psi_+ \cup  \psi_\vee$,
where $ \psi_+$ consists of all constraints of the form  
$\delta = \epsilon^+$ and $ \psi_\vee$ consists of the constraints of the form $\alpha\vee\beta = \gamma$.
In the latter constraints we assume $\alpha\neq\beta$, since constraints of the form
$\alpha \vee \alpha = \gamma$ can be eliminated by substitution.

Before we continue, we will further simplify $ \psi_+$.
Let $G_ \psi$ be the directed graph with a node $\delta$ for every
variable $\delta$ occurring in  $\psi$, and edges $\delta\to\epsilon$
for every constraint $\delta = \epsilon^+$ occurring in $ \psi_+$.
An \emph{undirected path} in $G_ \psi$ is a sequence of nodes connected
by edges and anti-edges.
The \emph{algebraic length} of an undirected path is the algebraic sum 
of the number of edges minus the number of anti-edges.
Clearly, for $ \psi_+$ to be solvable we must have that,
for all nodes $\delta$ and $\delta'$,
all undirected paths in $G_ \psi$ from $\delta$ to $\delta'$ have the same length.
The latter condition is also sufficient for the solvability of $ \psi_+$,
and can be tested in quadradic time. 
We assume from now on that $ \psi_+$ is solvable.

If two nodes of $G_ \psi$ are connected by an undirected path,
we define their \emph{algebraic distance} to be the algebraic length of
the undirected path, which is well-defined for $ \psi_+$ solvable. 
Given a node $\delta$ of $G_ \psi$, all nodes at the same algebraic distance $k$ from 
$\delta$ have the same value in any model of $ \psi_+$. 
This means that the corresponding variables can be considered to be equal.
As a consequence we can eliminate all but one of the nodes at 
algebraic distance $k$ from $\delta$, for each $\delta$ and $k$.
Without loss of generality we may therefore assume that $G_ \psi$ consists 
of linear paths that are mutually disjoint.
Models of $ \psi^+$ are uniquely determined by the values of 
one of the nodes on each of these linear paths, for example,
the \emph{sources}, i.e., the start nodes. If we use the notation $l + n$ for $l^{+\ldots +}$, the result of iterating the operation $\_^+$ on $l$ $n$ times. Then
the phrase `nodes $\alpha$ and $\alpha'$ are on the same path in $G_ \psi$'
means that, formally, there is some $n$ in $\NN$ such that
either $\alpha=\alpha'+n$ or $\alpha+n=\alpha'$ follows from $ \psi^+$
in equational logic with a rule for the injectivity of the successor operation.

We can now prove a so-called \emph{small model property}.
\begin{lemma}\label{lem:small-model}
Let   $\psi$ be a finite set of constraints in reduced form such that all paths in $G_ \psi$ are linear
and mutually disjoint. Let $K_{ \psi}$ be the number of occurrences of symbols $\_^+$ in  $\psi$.
If there is a model of  $\psi$, then there is a model with values at most $K_{ \psi}$.
\end{lemma}

\begin{proof}
Observe that $K_{ \psi}$ is the sum of the lengths of the paths in $G_ \psi$.
Let $M \models \psi$. If the interpretations of the paths $G_ \psi$
has a gap, say of length $k$, then we can construct another model $M' \models \psi$
in which all variables with value above the gap are lowered by $k$. By repeating this procedure we can close all gaps, and also arrange things such that
the lowest value of a variable is $0$. The resulting model
has values at most $K_{ \psi}$.
\end{proof}

\cref{lem:small-model} implies the decidability of solvability.
We will now describe an efficient search procedure finding a
model if there exists one. We first prove the following lemma.

\begin{lemma}\label{lem:model-search}
Let   $\psi$ be a finite set of constraints in reduced form such that all paths 
in $G_ \psi$ are linear and mutually disjoint.
Let $M$ be a model of  $\psi$ and $\rho$ a model of $ \psi^+$ such that $\rho\geq M$ (pointwise).
If $\rho$ is not a model of  $\psi$, then the assignment $\rho'$ defined in 
one of the ways below is also a model of $ \psi^+$ and satisfies $\rho'\geq M$.
Moreover, $\rho'(\alpha)<\rho(\alpha)$ for at least one variable.
\begin{enumerate}
\item Pick a constraint $\alpha\vee\beta = \gamma$ from  $\psi$ with
$(\alpha\vee\beta)\rho +n = \gamma\rho$ for some $n>0$, and define 
$\rho'(\gamma') = \rho(\gamma')-n$ for any $\gamma'$ on the same path as $\gamma$ in $G_ \psi$.
\item Pick a constraint $\alpha\vee\beta = \gamma$ from  $\psi$ with $\rho(\alpha)\geq\rho(\beta)$
and $(\alpha\vee\beta)\rho = \gamma\rho +n$ for some $n>0$, and  define 
$\rho'(\alpha') = \rho(\alpha') -n$ for any $\alpha'$ on the same path as $\alpha$ in $G_ \psi$.
If $\beta$ is not on the same path as $\alpha$ in $G_ \psi$ and $\rho(\beta)>\rho(\gamma)$, define also
$\rho'(\beta') = \rho(\beta') + \rho(\gamma) - \rho(\beta)$ 
for any $\beta'$ on the same path as $\beta$ in $G_ \psi$. Note that we have
$\rho'(\alpha) = \rho(\gamma)$. If $\alpha$ and $\beta$ are
not on the same path and $\rho(\beta)>\rho(\gamma)$, then we also have
$\rho'(\beta) = \rho(\gamma)$, otherwise we have $\rho'(\beta) = \rho(\beta)$.
\item Like the previous one with $\beta\vee\alpha = \gamma$.
\end{enumerate}
\end{lemma}

\begin{proof}
Let conditions be as above. We observe that we lowered all variables on one or two
paths of $G_ \psi$, so that $\rho'$ is a model of $ \psi^+$. In each case we
have to prove that $\rho'\geq M$.
We use that $\max$ is monotone in both its arguments.
\begin{enumerate}
\item Since $\rho$ and $M$ are both models of $ \psi^+$, it suffices to 
verify that $\rho'(\gamma)\geq M(\gamma)$. We have 
$\rho'(\gamma)= (\alpha\vee\beta)\rho \geq (\alpha\vee\beta)M = M(\gamma)$.
\item Since $\rho$ and $M$ are both models of $ \psi^+$, it suffices to 
verify that $\rho'(\alpha)\geq M(\alpha)$, and similarly for $\beta$. We have
$\rho'(\alpha)= \rho(\gamma)\geq M(\gamma) = (\alpha\vee\beta)M \geq M(\alpha)$.
Use $\rho'(\beta) = \rho(\gamma)$ and $(\alpha\vee\beta)M \geq M(\beta)$
if $\beta$ is not on the same path as $\alpha$ in $G_ \psi$ and $\rho(\beta)>\rho(\gamma)$. 
\item Similar to the previous case.
\end{enumerate}
\end{proof}

Assume  $\psi$ is a finite set of constraints in reduced form such that all paths 
in $G_ \psi$ are linear and mutually disjoint. By \cref{lem:small-model},
if  $\psi$ has a model, there is a model $M \leq K_ \psi$.
We start the search from the model $\rho$ of $ \psi^+$ that is constant $K_ \psi$
on the sources of the paths of $G_ \psi$.
In each step from $\rho$ to $\rho'$ in \cref{lem:model-search},
at least one variable is lowered. This can be done at most $V K_ \psi$ times,
where $V$ is the number of variables. So we will actually find the unique maximal
model $M$ with values at most $K_ \psi$, if there is a model at all.
Each step requires a pass through all constraints to evaluate them in the current assignment.
When properly implemented this can be done in $O(K_ \psi)$ time.
The whole decision procedure of first transforming to constraints in reduced
form and then testing for solvability takes $O(V K^2_ \psi)$ time.
(It may be possible to do better.) We have reached our goal:

\begin{theorem}\label{thm:P-solvability}
Deciding solvability of a finite set of universe constraints is polynomial.
\end{theorem}


\section{Related work}

Harper and Pollack \cite{HarperP91} consider the system $\CComega$, the Calculus of Constructions with an sequence of universes \`a la Russell. They consider both an externally indexed version and a version with level expressions which are either numbers or variables, and with constraints of the form $l < m$ and $l \leq m$. Chan has an algorithm for solving those constraints in $\Ordo(c,v^3)$, where $c$ is the number of constraints and $v$ is the number of level variables. They also consider the level synthesis problem in a version with an anonymous universe Type.

Huet \cite{Huet87} develops another algorithm for universe polymorphism in the Calculus of Constructions. He drops the assumption that the universes form a linearly-ordered cumulative hierarchy indexed by the natural numbers, and on this basis develops a more efficient consistency checking algorithm than Chan's.
%\begin{quotation}
%(cut-and-paste from Harper and Pollack)
%Huet, in an unpublished manuscript \cite{Huet87}, has independently developed an
%algorithm for handling universes in the Calculus of Constructions. His approach is to drop the assumption that the universes form a linearly-ordered
%cumulative hierarchy indexed by the natural numbers, and to consider instead a family of calculi in which there is some well-founded partial ordering
%of universes. The input language is correspondingly restricted so that specific universes are disallowed; only the anonymous universe Type may be
%used. The principal advantage of this approach over the one considered here
%is that the consistency checking algorithm is significantly more efficient than
%Chan's algorithm, reducing to an acyclicity check in a dependency graph of
%universe levels. 
%\end{quotation}

Assaf \cite{Assaf14} considers an alternative version of the calculus of
constructions where subtyping is explicit. This new system avoids problems related to coercions and dependent types by using the Tarski style
of universes and by introducing additional equations to reflect equality. In particular he adds an explicit cumulativity map $\T^0_1 : \UU_0 \to \UU_1$. He argues that "full reflection" is necessary to achieve the expressivity of Russell style. He introduces the explicit cumulative calculus of constructions (CC$\uparrow$) which is closely related to our system of externally indexed Tarski style universes.

\bibliographystyle{plain}
\bibliography{refs}

\end{document}
