%\documentclass[12pt,a4paper]{amsart}
\documentclass[11pt,a4paper]{article}
%\ifx\pdfpageheight\undefined\PassOptionsToPackage{dvips}{graphicx}\else%
%\PassOptionsToPackage{pdftex}{graphicx}
\PassOptionsToPackage{pdftex}{color}
%\fi

%\usepackage{diagrams}

%\usepackage[all]{xy}
\usepackage{url}
\usepackage{verbatim}
\usepackage{latexsym}
\usepackage{amssymb,amstext,amsmath,amsthm}
\usepackage{epsf}
\usepackage{epsfig}
% \usepackage{isolatin1}
\usepackage{a4wide}
\usepackage{verbatim}
\usepackage{proof}
\usepackage{latexsym}
%\usepackage{mytheorems}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}{Lemma}[theorem]
\newtheorem{proposition}{Proposition}[theorem]

\usepackage{float}
\floatstyle{boxed}
\restylefloat{figure}


%%%%%%%%%copied from SymmetryBook by Marc

% hyperref should be the package loaded last
\usepackage[backref=page,
            colorlinks,
            citecolor=linkcolor,
            linkcolor=linkcolor,
            urlcolor=linkcolor,
            unicode,
            pdfauthor={CAS},
            pdftitle={Symmetry},
            pdfsubject={Mathematics},
            pdfkeywords={type theory, group theory, univalence axiom}]{hyperref}
% - except for cleveref!
\usepackage[capitalize]{cleveref}
%\usepackage{xifthen}
\usepackage{xcolor}
\definecolor{linkcolor}{rgb}{0,0,0.5}

%%%%%%%%%
\def\oge{\leavevmode\raise
.3ex\hbox{$\scriptscriptstyle\langle\!\langle\,$}}
\def\feg{\leavevmode\raise
.3ex\hbox{$\scriptscriptstyle\,\rangle\!\rangle$}}

%%%%%%%%%
\newcommand\myfrac[2]{
 \begin{array}{c}
 #1 \\
 \hline \hline
 #2
\end{array}}


\newcommand*{\Scale}[2][4]{\scalebox{#1}{$#2$}}%
\newcommand*{\Resize}[2]{\resizebox{#1}{!}{$#2$}}

\newcommand{\II}{\mathbb{I}}
\newcommand{\refl}{\mathsf{refl}}
\newcommand{\mkbox}[1]{\ensuremath{#1}}


\newcommand{\Id}{\mathsf{Id}}
\newcommand{\conv}{=}
%\newcommand{\conv}{\mathsf{conv}}
\newcommand{\lam}[2]{{\langle}#1{\rangle}#2}
\def\NN{\mathsf{N}}
\def\UU{\mathsf{U}}
\def\JJ{\mathsf{J}}
\def\Level{\mathsf{Level}}
%\def\Type{\hbox{\sf Type}}
\def\ZERO{\mathsf{0}}
\def\SUCC{\mathsf{S}}

\newcommand{\type}{\mathsf{type}}
\newcommand{\N}{\mathsf{N}}
\newcommand{\Set}{\mathsf{Set}}
\newcommand{\El}{\mathsf{El}}
%\newcommand{\U}{\mathsf{U}} clashes with def's in new packages
\newcommand{\T}{\mathsf{T}}
\newcommand{\Usuper}{\UU_{\mathrm{super}}}
\newcommand{\Tsuper}{\T_{\mathrm{super}}}
%\newcommand{\conv}{\mathrm{conv}}
\newcommand{\idtoeq}{\mathsf{idtoeq}}
\newcommand{\isEquiv}{\mathsf{isEquiv}}
\newcommand{\ua}{\mathsf{ua}}
\newcommand{\UA}{\mathsf{UA}}
%\newcommand{\Level}{\mathrm{Level}}
\def\Constraint{\mathsf{Constraint}}
\def\Ordo{\mathcal{O}}

\def\Ctx{\mathrm{Ctx}}
\def\Ty{\mathrm{Ty}}
\def\Tm{\mathrm{Tm}}

\def\CComega{\mathrm{CC}^\omega}
\setlength{\oddsidemargin}{0in} % so, left margin is 1in
\setlength{\textwidth}{6.27in} % so, right margin is 1in
\setlength{\topmargin}{0in} % so, top margin is 1in
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\textheight}{9.19in} % so, foot margin is 1.5in
\setlength{\footskip}{.8in}

% Definition of \placetitle
% Want to do an alternative which takes arguments
% for the names, authors etc.

\newcommand{\natrec}{\mathsf{natrec}}
%\rightfooter{}
\newcommand{\set}[1]{\{#1\}}



\begin{document}

\title{A Note on Universe Polymorphism}

\author{Marc Bezem, Thierry Coquand, Peter Dybjer, Mart\'in Escard\'o}
\date{}
\maketitle

\begin{abstract}
We present rules for both externally and internally indexed sequences of universes \`a la Tarski with and without cumulativity. The rules for internally indexed universe levels are reminiscent of Agda's, although we do not have a {\em type} of universe levels. Instead we add a new judgment $l\ \Level$ meaning that $l$ is a universe level expression built up from variables $\alpha$ by a successor operation $l^+$ and suprema $l \vee m$. We first introduce rules for ML-style universe polymorphism, where judgments are indexed by level variables. Then we add rules for level-indexed product types $[\alpha]A$ meaning "$A$ holds for all universe levels $\alpha$". We also present Voevodsky's proposal for a system with level constraints and an algorithm for solving such constraints. Furthermore, we survey the historical evolution of universes in type theory. Among other things, we discuss the relationship between the level-indexed and the externally indexed theories as well as with Palmgren's super universe.
\end{abstract}

\section*{Related work}

Check related work of Ali Assaf, Luo, Mendler, Voevodsky, Huet, Harper and Pollack, Sozeau.

\section{Introduction}

This note records discussions between the authors concerning the appropriate setting for univalent mathematics in Martin Löf type theory.

The first published version of Martin-Löf's theory \cite{martinlof:predicative} introduces a countable sequence of universes
$$
\UU_0 : \UU_1 : \UU_2 : \cdots
$$
When developing mathematics inside this theory, most types will belong to $\UU_0$ although a significant minority belongs to $\UU_1$. Occasionally one may need a type in $\UU_2$ and, in rare cases, types at even higher universe levels.\footnote{Universes become more important in a predicative framework than in an impredicative one. Thierry will write something about ths.} This suggests that it might be feasible for a users of type theory to explicitly assign universe levels to their types, and whenever necessary repeat definitions when they are needed on different levels. However, the number of copies of definitions does not only grow with the level, but also with the number of type arguments in the definition of a type former. As a consequence, Huet \cite{Huet87} and Harper and Pollack \cite{HarperP91} introduced {\em universe polymorphism}. However, the precise formulation and implementation of universe polymorphism has been a subject of much debate, and different proof assistants use different approaches. \footnote{de Moura said that universe level inference in Coq is more costly than type-checking.}

%\section{What is a univalent type theory?}

Universe polymorphism has also been a common topic of discussion in the context of Voevodsky's univalent foundations. The {\em univalence axiom} states that for any two types $X,Y$ the canonical map
$$
\idtoeq_{X,Y} : (X=Y)\to (X\simeq Y)
$$
is an equivalence. Formally, the univalence axiom is an axiom (or axiom scheme) added to Martin-Löf type theory. If we work in the above-mentioned setting with a countable sequence of universes, a universe $\UU_n$ is {\em univalent} provided for all $X,Y : \UU_n$ the canonical map $\idtoeq_{X,Y}$ is an equivalence. Let $\UA_n$ be the type expressing the univalence of $\UU_n$, and
$$
\ua_n : \UA_n
$$
for $n = 0,1,\ldots$, be a sequence of constants expressing the instances of the univalence axiom. We note that $X = Y : \UU_{n+1}$ and $X\simeq Y : \UU_n$ and hence $\UA_n$ is in $\UU_{n+1}$. If we have universe polymorphism expressed as quantification over universe levels, as in the Agda system, then we can express univalence of all universes as one typing:
$$
\ua : (l : \Level) \to \UA_l
$$
in Agda's notation.

In this note we shall present some extensions of type theory which are loosely based on Agda's level-mechanism. We will also present Voevodsky's system which maintains constraints between level-variables, and an algorithm for solving those constraints.

\paragraph{Plan.} We begin by providing some historical background about the evolution of universes in type theory. In particular, we shall discuss Palmgren's next universe operator and super universe, and point out that the super universe makes it possible to define an internally quantified sequence of universes. We shall also discuss how the rules for universes are formalized in terms of operations and equations extending the generalised algebraic theory of categories with families. Furthermore, we discuss the role of universes in Martin-Löf's logical framework and how this differs from Agda's logical framework. In Section \ref{external} we state the rules for a basic version of Martin-Löf type theory with $\Pi, \Sigma, \NN$, an identity type former $\Id$, and an externally indexed sequences of universes $\UU_n, \T_n$ \`a la Tarski. We then add cumulativity rules for these universes. In Section \ref{internal} we introduce the notion of universe level, and let judgments depend not only on a context of ordinary variables, but also on a list of level variables $\alpha_1, \ldots, \alpha_k$, giving rise to a theory with level polymorphism. This is a kind of ML-polymorphism since we only quantify over global level variables. We then further extend the theory with level-indexed products of types $[\alpha]A$. In Section \ref{constraints} we present Voevodsky's proposal with constraints between level variables. We also propose an algorithm for solving those constraints.

\section{A brief history of universes in type theory}

\subsection{External sequences of universes}

Martin-Löf \cite{martinlof:predicative} introduced the above-mentioned version of his intuitionistic type theory with an external countable sequence of universes. In this theory the only judgment is  $\Gamma \vdash a : A$. Moreover, it has an untyped notion of conversion $a\ \conv\ a'$. There is no judgment $A\ \type$; since a type is an $A : \UU_n$ for some $n$. Universes are here \`a la Russell. However, there is no rule of cumulativity ensuring that $A : \UU_m$ implies $A : \UU_n$ for $m \leq n$.

Martin-Löf \cite{martinlof:hannover} changed the judgment structure and added the judgment form $\Gamma \vdash A\ \type$\footnote{We should be systematic with respect to notation: shall we show all the old notations or the notations we use nowadays?} and replaced the untyped conversion judgments with typed equality judgments $\Gamma \vdash a = a' : A$ and $\Gamma \vdash A = A'$. There is still an external sequence of universes \`a la Russell. A cumulativity rule was also added.

Martin-Löf \cite{martinlof:padova} gave an alternative formulation of the first universe $\UU_0$ \`a la Tarski with decoding $\T_0$ \footnote{Did he discuss two universes?}.
Palmgren \cite{palmgren:venice} then proposed two alternatives for rules for the external sequence of universes $\UU_n$ \`a la Tarski with decodings $\T_n$. 

The first version is entitled "universes as full reflection" and was only outlined for the first and the second universe. We will give a full presentation of this theory in Section \ref{external}. In this version there is a cumulativity map $\T_0^1 : \UU_0 \to \UU_1$ which is defined by recursion on the way the elements of $\UU_0$ are defined. For example, assume that $\pi_0$ and $\pi_1$ are the functions which represent the closure under $\Pi$ of $\UU_0$ and $\UU_1$, respectively . Then one of the defining equations of $\T_0^1$ is
$$
\T_0^1\, (\pi_0\,a\, b) = \pi_1\,(\T_0^1\,a)\,(\lambda x.\T_0^1\,(b\,x))
$$
However, the right hand side of this equations is ill-typed, unless we stipulate the following judgmental equality
$$
\T_1\, (\T_0^1\, a) = \T_0\, a
$$
Note however that this equation depends on $\T_0^1$ itself, the function we are in the process of defining! If we nevertheless allow the ill-typed equation above, it will follow that the second equation will be valid for all $a : \UU_0$, that is, it will be valid extensionally. We could even argue that we only need to know this equation for $\T_0^1\, a$, when defining $\T_0^1\, (\pi_0\,a\, b)$, so we could claim that this equation is known when it is needed. Would it be correct to say that this is a "definitional equality"? In one sense no, because $\T_1$ was already defined earlier, and we cannot stipulate its effect on $\T_0^1\, a$. On the other hand it seems that adding this equation as a judgmental equality does not destroy the decidability of the system.

Palmgren's second version of the external sequence is entitled "universes as uniform constructions". Here the map $\T_0^1 : \UU_0 \to \UU_1$ is a constructor for the second universe $\UU_1$. However, this means that we do not have full reflection: $\UU_1$ contains canonical elements which have no counterpart as canonical types.

\subsection{Internal sequences of universes and the super universe}

Palmgren \cite{palmgren:venice} went on to internalize the construction of the infinite sequence of universes  \`a la Tarski. To this end he introduced the {\em next-universe operator}, which given a family of types $U, T$, constructs a new family of types $U^+, T^+$, such that $ \UU_{n+1} = \UU_n^+$ and $\T_{n+1} = \T_n^+$.

Furthermore, Palmgren introduced a {\em super universe} (\`a la Tarski), which is a type containing a code for the first universe and is closed under the next-universe operator as well as under all the usual small type formers. In this theory we can define an internal sequence of universes $n : \NN \vdash \UU_n$, and also express univalence of this sequence as one typing:
$$
\ua : \Pi_{n : \N}\, \UA_n
$$
using the ordinary $\Pi$-type former of type theory.

In fact, we point out that the notion of "universe" is rather general - any inductive-recursive definition can be viewed as a universe closed under some given operations. Thus for univalence, it suffices to introduce a {\em minimal super universe} with $\N$ as the type of codes, and with decoding $\Tsuper$,
such that $\Tsuper\,0$ is the empty universe and $\Tsuper\,(n + 1)$ is the next universe above $\Tsuper\,n$. (In this way the first universe $\UU_0$ is represented by the next universe above the empty universe.) Thus all we need to add to Martin-Löf type theory without universes is (i) the empty universe, (ii) the next-universe operator, (iii) the minimal super universe.

%We remark that in type theory with Setzer's {\em Mahlo universe} we get Palmgren's super universe as a special case.

\subsection{The generalised algebraic theory of type theory with universes}

Models of type theory can be expressed as categories with families (cwfs) with extra structure for modelling the rules for type formers.  A key feature of cwfs is that they can be expressed as models of a generalised algebraic theory in the sense of Cartmell \cite{cartmell:apal}, and also that the extra structure for type formers can be expressed by adding more operations and equations to the generalised algebraic theory of cwfs. When we add new rules to type theory, it is desirable that the corresponding extra structure on  models also can be expressed in terms of operations and equations to the generalised algebraic theory of cwfs. We should therefore ask ourselves which the extra structure needed for modelling universe hierarchies.

For example, we can formulate the new operations and equations for universes that need to be added to the generalised algebraic theory of cwfs. For example, $\UU_0,\T_0,\UU_1, \T_1,$ and $\T_0^1$ can be added as new operations, and we can add the defining equations for $\T_0,\UU_1, \T_1,\T_0^1$, including the equation
$
\T_1\, (\T_0^1\, a) = \T_0\, a
$
which we discussed above.
For example, we have
\begin{eqnarray*}
\UU_0 &: &(\Gamma : \Ctx) \to \Ty(\Gamma)\\
\T_0 &: &(\Gamma : \Ctx ; A : \Tm(\Gamma,\UU_0(\Gamma)))\to \Ty(\Gamma)
\end{eqnarray*}

\subsection{Universes in Martin-Löf's logical framework}

The rules for the various universes \`a la Tarski that we discussed above can also be formulated using Martin-Löf's logical framework \cite{Martinlof86,NordstromPS90}. This framework has $\Pi$-types (written $(x : A)B$ by Martin-Löf and abbreviated $(A)B$ when $B$ does not depend on $x$.) and a type $\Set$ which is a "universe" with a special role. We will here use the formulation \`a la Tarski of $\Set$ with decoding $\El$, but there is also a formulation \`a la Russell which often used in practice. The formation, introduction, and elimination rules of type theory are formulated as typings of constants $c : A$, and the equality rules are formulated as equations $a = a' : A$. The idea is that $A : \Set$ in the logical framework version represents $A$ {\em type} in the earlier formulations of type theory, and the {\em typing} $f : (x : A)B$ represents the {\em rule} that if $a : A$ then $f\,a : B$.

For example, the formation rule for $\Pi$-sets (as opposed to types) is represented by the typing
\begin{eqnarray*}
\Pi &:& (A:\Set)((\El\,A)\,\Set)\,\Set
\end{eqnarray*}
and the formation rules for first universe (\`a la Tarski) are represented by the typings
\begin{eqnarray*}
\UU_0 &: &\Set\\
\T_0 &:& (\El\,\UU_0)\,\Set
\end{eqnarray*}
The first typing represents the rule that $\UU_0$ is a type in the original version of type theory, and the second typing represents the rule that if $a : \UU_0$, then $\T_0\,a$ is a type. We also have constants for the introduction rules for $\UU_0$ and equality rules for their decodings. For example, closure under $\pi$ is expressed by
\begin{eqnarray*}
\pi_0 &:& (a:\El\, \UU_0)(\El\, (\T_0\, a))(\El\, \UU_0)\,\El\, \UU_0
\end{eqnarray*}
with decoding
\begin{eqnarray*}
\T_0\, (\pi_0\, a\, b) &=& \Pi (\T_0\, a) ((x)\,\T_0\, (b\, x))
\end{eqnarray*}
In this system we have three levels of products: $\pi\,a\,b : \UU_0$, $\Pi\,A\,B : \Set$ and the type $(x : A)B$.
%
%
%There is no problem adding further constants and equations for the next-universe operator and the minimal super universe to the logical framework.
%\begin{eqnarray*}
%\UU_n &: &\Set\\
%\T_n &:& \El\,\UU_n \to \Set
%\end{eqnarray*}
%Closure under $\pi$ is expressed by
%\begin{eqnarray*}
%\pi_n &:& (X:\El\, \UU_n) \to (\El\, (\T_n\, X) \to \El\, \UU_n) \to \El\, \UU_n \\
%\T_n\, (\pi X F) &=& \Pi (\T_n\, X) (\ (x: \El\, (\T_n\, X)) \T_n\, (F x))
%\end{eqnarray*}
%
% Also we have Pi sets with a new constructor Lambda for functions

\section{Universes in Agda}

So far we have discussed the formulation of the univalence axiom in what might be called "standard" versions of Martin-Löf type theory, where the \`a la Tarski rules for universes and super universes follow the general pattern of inductive-recursive definitions in type theory. (Recall however again that the equation
$
\T_0^1\, (\pi_0\,a\, b) = \pi_1\,(\T_0^1\,a)\,(\lambda x.\T_0^1\,(b\,x))
$
which is a function defined by universe elimination on $\UU_0$ does not type-check unless we stipulate $\T_1\, (\T_0^1\, a) = \T_0\, a$.)


The proof assistant Agda is loosely based on Martin-Löf's logical framework, but with several modifications which are relevant to our discussion. Firstly, it is based on a "logical framework" which is different from Martin-Löf's. It has the following features:
\begin{itemize}
\item It has a sequence of universes  $$\Set_0 : \Set_1 : \Set_2 : \cdots$$  \`a la Russell.
\item It has built in dependent function types written $\Gamma \vdash (x : A)\to B : \Set_n$ for $\Gamma \vdash A : \Set_n$ and $\Gamma , x : A \vdash B : \Set_n$
\item It has a special type $\Level$ of universe levels, which makes it possible to define {\em universe polymorphic} types and terms.
\end{itemize}
This is a logical framework in the sense that we can add new concepts by adding new constants with their types $c : A$, and also add new equations $a = a' : A$ in the same way as in Martin-Löf's logical framework. For example, we can define universes \`a la Tarski in a similar way as we showed above for Martin-Löf's logical framework:
\begin{eqnarray*}
\UU_n &: &\Set_n\\
\T_n &:& \UU_n \to \Set_n
\end{eqnarray*}
However, most Agda users only make use of the built in universes $\Set_n$, and do not introduce such "internal" universes as $\UU_n, \T_n$. Moreover, most Agda users only make use of the built in function types $(x : A)\to B : \Set_n$ and don't introduce "user defined data types" such as
\begin{eqnarray*}
\Pi_n &:& (A:\Set_n) \to (A \to \Set_n) \to \Set_n
\end{eqnarray*}
for representing $\Pi$-types as we did in Martin-Löf's logical framework. As a consequence it is more appropriate to think of Agda's sequence of universes as analogous to the sequence of universes  \`a la Russell $ \UU_0 : \UU_1 : \UU_2 : \cdots$ in the early versions of Martin-Löf type theory. However, since Agda has a type $\Level$ of levels, we can define a functions $i : \N \to \Level$, and hence the family $n : \N \vdash \Set\, (i\, n)$ analogous to the family $n : \N \vdash \Tsuper\,n$ in type theory with a (minimal) super universe. However, Agda does not have a type analogous to $\Usuper$, only a "kind" $\Set_\omega$ which is not a type. See the Agda wiki for more explanation.

In the following section we shall give the rules for a version of type theory with a system universes with level quantification. Although it is similar to Agda's system, it differs in important respects, since we shall not introduce a {\em type} of levels, and the kind $\Set_\omega$.

\section{A type theory with an external sequence of universes}\label{external}

As already mentioned the rules for the minimal super universe follows the pattern of inductive-recursive definitions, and is a natural candidate for a clean formulation of a type theory which allows quantification over countably many universe levels. Thus the universe levels are members of the type $\N$, and the operation $l \vee m$ is the maximum operation on $\N$, which can be defined by induction on $l$ or $m$. Unfortunately, we have to make a choice between $m$ and $n$ and hence we not all equations of level arithmetic (making levels a sup-semi-lattice) will be definitional.

For this reason, we will here propose an alternative formulation, where we do not have a {\em type} of levels. Instead we have new judgments $l \Level$, meaning that $l$ is a level expression, and $l = m$ meaning that $l$ and $m$ are definitionally equal levels . We have a maximum operation $\vee$ on levels such that levels become a sup-semilattice up to definitional equality. We also remark that the proof theoretic strength of this alternative system is less than the system with a minimal super universe.

\subsection*{Rules for a basic type theory}

We begin by listing the rules for a basic type theory with $\Pi, \Sigma, \N,$ and $\Id$
$$
\frac{\Gamma\vdash A}{\Gamma,x:A\vdash}~~~~~~\frac{}{()\vdash}~~~~~~~
\frac{\Gamma\vdash}{\Gamma\vdash x:A}~(x\!:\! A~in~\Gamma)
$$
The judgment $\Gamma\vdash A$ expresses that $A$ is a type in context $\Gamma$.
We may write it $A~\type~(\Gamma)$ and may omit the global context $\Gamma$.
For instance, the rules
$$
%\frac{\Gamma,x:A\vdash B}{\Gamma\vdash \Pi (x:A) B}~~~~~~~~~
\frac{\Gamma\vdash A~~~~~~\Gamma,x:A\vdash B}{\Gamma\vdash \Pi (x:A) B}~~~~~~~~~
\frac{\Gamma,x:A\vdash b:B}{\Gamma\vdash \lambda (x:A) c:\Pi (x:A) B}~~~~~~~~
\frac{\Gamma\vdash c:\Pi (x:A) B~~~~~~\Gamma\vdash a:A}
     {\Gamma\vdash c~a:B(a/x)}
$$
can be written
$$
%\frac{\Gamma,x:A\vdash B}{\Gamma\vdash \Pi (x:A) B}~~~~~~~~~
\frac{A~\type~~~~~~B~\type~(x:A)}{\Pi (x:A) B~\type}~~~~~~~~~
\frac{b:B~(x:A)}{\lambda (x:A) b:\Pi (x:A) B}~~~~~~~~
\frac{c:\Pi (x:A) B~~~~~~a:A}
     {c~a:B(a/x)}
$$

We also have
$$
%\frac{\Gamma,x:A\vdash B}{\Gamma\vdash \Pi (x:A) B}~~~~~~~~~
\frac{A~\type~~~~~~B~\type~(x:A)}{\Sigma (x:A) B~\type}~~~~~~~~~
\frac{a:A~~~~~~b:B(a/x)}{(a,b):\Sigma (x:A) B}~~~~~~~~
\frac{c:\Sigma (x:A) B}{c.1:A}~~~~~~~
\frac{c:\Sigma (x:A) B}{c.2:B(c.1/x)}
$$

We write $\conv$ for definitional equality (or conversion). The main conversion rules are
$$
\frac{ a:A~~~~~~ A~ \conv~ B}{ a:B}~~~~~~~~~
\frac{ a ~\conv~a':A~~~~~~ A  ~\conv~ B}{ a ~\conv~a':B}
$$
$$
\frac{b:B~(x:A)~~~~~~~~ a:A}{ (\lambda (x:A)b)~a  ~\conv~ b(a/x):B(a/x)}
~~~~~~~
\frac{f~x = g~x:B~(x:A)}{ f = g : \Pi (x:A)B}
$$
$$
\frac{ a:A~~~~~~ b:B(a/x)}{ (a,b).1  ~\conv~ a:A}
~~~~~~~
\frac{ a:A~~~~~~ b:B(a/x)}{ (a,b).2  ~\conv~ b:B(a/x)}~~~~~~
\frac{ a.1 = a'.1:A~~~~~~~ a.2 = a'.2:B(t.1/x)}{ a = a' : \Sigma (x:A)B}
$$

We can introduce data types: the type of natural numbers $\NN$ has
constructors $\ZERO:\NN$ and $\SUCC:\NN\rightarrow\NN$ and elimination rules
$$
\frac{P~\type~(x:\NN)~~~~a:P(\ZERO/x)~~~~~g:\Pi (x:\NN)P\rightarrow P(\SUCC~x/x)}{\natrec(a,g):\Pi (x:\NN)P}
$$
with conversion rules $\natrec(a,g)~\ZERO = a$ and $\natrec(a,g)~(\SUCC~x) = g~x~(\natrec(a,g)~x)$.\footnote{change to version with $\natrec(a,g,n)$?}

We also have a type $\Id~A~a_0~a_1$ for $a_0:A$ and $a_1:A$ with $\refl~a:\Id~A~a~a$
and the elimination rule
$$\frac{a:A~~~~~C~\type~(x:A,p:\Id~A~a~x)~~~~~d:C(a/x,\refl~a/p)}{\JJ (a,d):\Pi (x:A)(p:\Id~A~a~x)C}$$
with the conversion rule $\JJ(a,d)~a~(\refl~a) = d$.

\subsection*{Rules for an external sequence of universes}

We will now present a complete set of rules for "universes as full reflections". We first present a version without cumulativity.
$$
\UU_n~\type~~~~~~
\frac{A:\UU_{n}}{\T_{n}(A)~\type}
$$
$$
\frac{A:\UU_{n}~~~~~~B:\T_{n}(A)\rightarrow \UU_{m}}
     {\Pi^{n,m} A B:\UU_{n\vee m}}~~~~~~~~~
\frac{A:\UU_{n}~~~~~~B:\T_{n}(A)\rightarrow \UU_{m}}
     {\Sigma^{n,m} A B:\UU_{n\vee m}}~~~~~~~~~
$$
where $n$ and $m$ are external natural numbers, and $n \vee m$ is the maximum of $n$ and $m$. This means for example, that $\UU_n~\type$ is a {\em schema}, yielding one rule for each $n$.
The conversion rules are
$$
\T_{n\vee m}~(\Pi^{n,m} A B) = \Pi (x:\T_{n}(A)) \T_{m}(B~x)~~~~~~~
\T_{n\vee m}~(\Sigma^{n,m} A B) = \Sigma (x:\T_{n}(A)) \T_{m}(B~x)~~~~~~~
$$
Furthermore we have $$\NN^{n}:\UU_{n}$$
$$\T_{n}(\NN^{n}) = \NN$$
and
$$
\frac{A:\UU_n~~~~~~a_0:\T_n(A)~~~~~~a_1:\T_n(A)}
{\Id^n~A~a_0~a_1:\UU_n}
$$
$$\T_n(\Id^n~A~a_0~a_1) = \Id~\T_n(A)~a_0~a_1$$
and a code for the previous universe
$${\UU^{n}}:\UU_{n + 1}$$
$$\T_{n + 1}({\UU^{n}}) = \UU_{n}$$

Note that $\UU_p, \T_p$ is a separate inductive-recursive definition for each $p$ with one introduction rule for each $\Pi^{n,m}$ and $\Sigma^{n,m}$ such that $p = m \vee n$ and introduction rules for $\NN^p, \Id^p$, and for $\UU^{p-1}$ provided $p \geq 1$.
%\subsection*{Rules for cumulativity}
%
%With cumulativity, we introduce an operation
%$$
%\frac{A:\UU_{n}}
%{\T_{n}^{m}(A):\UU_{m}}
%n\leqslant m
%$$
%We can also formulate the side condition as an equaton $m = n \vee m$.
%We require
%\begin{eqnarray*}
%\T_m(\T_{n}^{m}(A)) &=& \T_{n}(A)
%\end{eqnarray*}
%and
%\begin{eqnarray*}
%T_{n}^{m}(\NN^{n}) &=& \NN^{m}
%\end{eqnarray*}
%
%We add $$
%T_{n}^m(A) = A
%$$
%if $n = m$
%and $$T_{m}^n\T_{n}^m = T_n^n$$ if $n\leqslant m\leqslant n$.
%
%We can then simplify the product and sum rules to
%$$
%\frac{A:\UU_{n}~~~~~~B:\T_{n}(A)\rightarrow \UU_{n}}
%     {\Pi^{n} A B:\UU_{n}}~~~~~~~~~
%\frac{A:\UU_{n}~~~~~~B:\T_{n}(A)\rightarrow \UU_{n}}
%     {\Sigma^{n} A B:\UU_{n}}~~~~~~~~~
%$$
%with conversion rules
%$$
%\T_{n}~(\Pi^{n} A B) = \Pi (x:\T_{n}(A)) \T_{n}(B~x)~~~~~~~
%\T_{n}~(\Sigma^{n} A B) = \Sigma (x:\T_{n}(A)) \T_{n}(B~x)~~~~~~~
%$$
%and
%$$
%\T_{n}^{m}~(\Pi^{n} A B) = \Pi^{m} \T_{n}^{m}(A) (\lambda (x:\T_{n}(A))\T_{n}^{m}(B~x))~~~~~~
%\T_{n}^{m}~(\Sigma^{n} A B) = \Sigma^{m} \T_{n}^{m}(A) (\lambda (x:\T_{n}(A))\T_{n}^{m}(B~x))~~~~~~
%$$
%
\subsection*{Rules for cumulativity}

We define an operation which injects elements of a lower universe into a higher universe:
$$
\frac{A:\UU_{n}}
{\T_{n}^{m}(A):\UU_{m}}
n < m
$$
We can also formulate the side condition as an equaton $m = n^+ \vee m$.
We postulate the conversion (cf the discussion of Palmgren's rules for full reflection in Section ?):
\begin{eqnarray*}
\T_m(\T_{n}^{m}(A)) &=& \T_{n}(A)
\end{eqnarray*}
and the decoding conversion\footnote{We should check our use of "conversion" vs "definitional equality" throughout the document.}
\begin{eqnarray*}
\T_{n}^{m}(\NN^{n}) &=& \NN^{m}
\end{eqnarray*}
In the presence of cumulativity we can simplify the product and sum rules to
$$
\frac{A:\UU_{n}~~~~~~B:\T_{n}(A)\rightarrow \UU_{n}}
     {\Pi^{n} A B:\UU_{n}}~~~~~~~~~
\frac{A:\UU_{n}~~~~~~B:\T_{n}(A)\rightarrow \UU_{n}}
     {\Sigma^{n} A B:\UU_{n}}~~~~~~~~~
$$
with conversion rules
$$
\T_{n}~(\Pi^{n} A B) = \Pi (x:\T_{n}(A)) \T_{n}(B~x)~~~~~~~
\T_{n}~(\Sigma^{n} A B) = \Sigma (x:\T_{n}(A)) \T_{n}(B~x)~~~~~~~
$$
and
$$
\T_{n}^{m}~(\Pi^{n} A B) = \Pi^{m} \T_{n}^{m}(A) (\lambda (x:\T_{n}(A))\T_{n}^{m}(B~x))~~~~~~
\T_{n}^{m}~(\Sigma^{n} A B) = \Sigma^{m} \T_{n}^{m}(A) (\lambda (x:\T_{n}(A))\T_{n}^{m}(B~x))~~~~~~
$$

The problem with this approach is that we have to {\em duplicate} definitions that follow
the same pattern. For instance, we have the identity function $\lambda (X:\UU_n)(x:\T_n(X))x$
of type $\Pi (X:\UU_n)(\T_n(X)\rightarrow \T_n(X))$ that can be defined for $n = 0,1,\dots$
The systems in the next sections address this issue.

\section{A type theory with universe levels and polymorphism }\label{internal}

We introduce {\em universe level} expressions: we write $\alpha,\beta,\dots$
for {\em level variables}, and $l,m,\dots$ for {\em level expressions} which are built from level variables
by suprema $l \vee m$ and the next level operation $l^+$.
Level expressions form a sup semilattice $l\vee m$
with a next level operation $l^+$ such that $l \vee l^+ = l^+$
and $(l\vee m)^+ = l^+\vee m^+$. (We don't seem to need a $0$ element.)
%As expressed in \cite{VV}, this is essentially a tropical (max-plus)
%semiring, except that we don't actually seem to need a $0$ element.

We have a new context extension operation adding a fresh level variable $\Gamma,\alpha~\Level$
to a given context.
$$
\frac{}{\alpha~\Level~(\Gamma)}(\alpha~in~\Gamma)~~~~~~
\frac{l~\Level~~~~~m~\Level}{l\vee m~\Level}~~~~~~
\frac{l~\Level}{l^+~\Level}~~~~~~
$$
We can now replace the rule schemata for externally indexed universes by corresponding rules which are internally indexed by level expressions.
$$
\frac{l~\Level}{\UU_{l}~\type}~~~~~~
\frac{A:\UU_{l}}{\T_{l}(A)~\type}~~~~~~
$$
$$
\frac{A:\UU_{l}~~~~~~B:\T_{l}(A)\rightarrow \UU_{m}}
     {\Pi^{l,m} A B:\UU_{l\vee m}}~~~~~~~~~
\frac{A:\UU_{l}~~~~~~B:\T_{l}(A)\rightarrow \UU_{m}}
     {\Sigma^{l,m} A B:\UU_{l\vee m}}~~~~~~~~~
$$
with conversion rules
$$
\T_{l\vee m}~(\Pi^{l,m} A B) = \Pi (x:\T_{l}(A)) \T_{m}(B~x)~~~~~~~
\T_{l\vee m}~(\Sigma^{l,m} A B) = \Sigma (x:\T_{l}(A)) \T_{m}(B~x)~~~~~~~
$$
Furthermore we have $$\NN^{l}:\UU_{l}$$
$$\T_{l}(\NN^{l}) = \NN$$
and
$$
\frac{A:\UU_l~~~~~~a_0:\T_l(A)~~~~~~a_1:\T_l(A)}
{\Id^l~A~a_0~a_1:\UU_l}
$$
$$\T_l(\Id^l~A~a_0~a_1) = \Id~\T_l(A)~a_0~a_1$$
and a code for the previous universe
$${\UU^{l}}:\UU_{l + 1}$$
$$\T_{l + 1}({\UU^{l}}) = \UU_{l}$$
Note that all the rules are completely analogous to the rules for externally indexed universes with external numbers replaced by internal levels.
%
%\medskip
%
%We also have ${\UU^{l}}:\UU_{l^+}$ with
%$\T_{l^+}({\UU^{l}}) = \UU_{l}$.
%
%\medskip
%
%For data types, we introduce $\NN^{l}:\UU_{l}$ with the conversion rule
%$\T_{l}(\NN^{l}) = \NN$.
%
%We have $\Id^l~A~a_0~a_1:\UU_l$ for $A:\UU_l$ and $a_0:\T_l(A)$ and $a_1:\T_l(A)$
%with $\T_l(\Id^l~A~a_0~a_1) = \Id~\T_l(A)~a_0~a_1$.
%
%\medskip
%

The following rule should be admissible:
we can derive $A = B : \UU_l$ from $\T_l(A) = \T_l(B)$.
 It expresses that $\T_l$ is an embedding from the collection of elements of $\UU_l$
 to the collection of types.
 (Voevodsky \cite[Rule 20 on p. 17]{VV} adds this as an internal rule, but then the system is not
 generalized algebraic anymore.)

It should be the case that if $a :\NN$ in a context with only level variables
then $a$ is convertible to a numeral.

In such a system we can state that all universes are univalent as a type and the
fact that if all universes are univalent then they all satisfy function extensionality.

We can also add rules for cumulativity which are completely analogous to those for the internally indexed universes.

\paragraph{Interpreting the level-indexed system in the system with externally indexed universes.}

A judgment in the level-indexed system can be interpreted in the the externally indexed system relative to an assignment $\rho$ of external natural numbers to level variables. We simply replace each level expression in the judgment by the corresponding natural number obtained by letting $l^+\,\rho = l\,\rho+1$ and $(l \vee m)\,\rho = \max(l\,\rho,m\,\rho)$.

%
%
%\subsection*{Cumulativity}
%
%We introduce an operation $\T_{l}^{m}(A):\UU_{m}$ if $A:\UU_{l}$
%and $l\leqslant m$ (i.e. $m = l\vee m$).
%
%We require $\T_{m}(\T_{l}^{m}(A)) = \T_{l}(A)$
%and $\T_{l}^{m}(\NN^{l}) = \NN^{m}$.
%
%We add $\T_{l}^m(A) = A$ if $l = m$
%and $\T_{m}^n\T_{l}^m = \T_l^n$ if $l\leqslant m\leqslant n$.
%
%We can then simplify the product and sum rules to
%
%$$
%\frac{A:\UU_{l}~~~~~~B:\T_{l}(A)\rightarrow \UU_{l}}
%     {\Pi^{l} A B:\UU_{l}}~~~~~~~~~
%\frac{A:\UU_{l}~~~~~~B:\T_{l}(A)\rightarrow \UU_{l}}
%     {\Sigma^{l} A B:\UU_{l}}~~~~~~~~~
%$$
%with conversion rules
%$$
%\T_{l}~(\Pi^{l} A B) = \Pi (x:\T_{l}(A)) \T_{l}(B~x)~~~~~~~
%\T_{l}~(\Sigma^{l} A B) = \Sigma (x:\T_{l}(A)) \T_{l}(B~x)~~~~~~~
%$$
%and
%$$
%\T_{l}^{m}~(\Pi^{l} A B) = \Pi^{m} \T_{l}^{m}(A) (\lambda (x:\T_{l}(A))\T_{l}^{m}(B~x))~~~~~~
%\T_{l}^{m}~(\Sigma^{l} A B) = \Sigma^{m} \T_{l}^{m}(A) (\lambda (x:\T_{l}(A))\T_{l}^{m}(B~x))~~~~~~
%$$

\subsection*{Rules for level-indexed products}

In Agda $\Level$ is a type, and it is thus possible to form level-indexed products of types. In our system $\Level$ is not a type, so if we want to be able to form level-indexed products we can extend the system with the following rules:
$$
\frac{A~\type~(\alpha~\Level)}{[\alpha]A~\type}~~~~~~~
\frac{t:[\alpha]A~~~~~l~\Level}
     {t~l:A(l/\alpha)}~~~~~~~~~
\frac{u:A~(\alpha~\Level)}{\lam{\alpha}{u}: [\alpha]A}~~~~~
\frac{t~\alpha = u~\alpha:A~(\alpha~\Level)}{t = u:[\alpha]A}
$$
with conversion rule $(\lam{\alpha}{u})~l = u(l/\alpha)$.

In this system all functions in $[\alpha]\NN$
should be constant. Example of use of this system? (See Martin's mail.)

\paragraph{Interpreting the system with levels into extensional type theory with a super universe.} We can interpret the theory with rules for level-indexed products in extensional type theory with a (minimal) super universe. Levels will be interpreted by internal natural numbers $n : \NN$, and level-indexed products $[\alpha]A$ will be interpreted by ordinary indexed products $\Pi_{n : \NN}A$. Level application and level abstraction will be interpreted as ordinary application and abstraction.

Note that in intensional type theory, we will not be able to justify all the laws for level expressions as definitional equalities.

\section{A system with level constraints}\label{constraints}

We try to describe the approach in \cite{VV} using our notation.

We introduce a further judgement for {\em constraints}. A constraint is
a finite set of equations $l = m$ between given levels. Thus we have
$$
\frac{l_1~m_1~\dots~l_k~m_k~\Level}{l_1 = m_1,\dots,l_k = m_k~\Constraint}
$$
We write $l\leqslant m$ for $l\vee m = m$.

We then have a new context extension $\Gamma,\psi$ if $\psi$ is a contraint in $\Gamma$.

Finally we have the judgement $\psi~(\Gamma)$ which expresses that the constraint $\psi$
holds in $\Gamma$. For instance we have $\alpha^+\leqslant\beta^+~(\alpha\leqslant\beta)$.

We then have judgements of the form
$$
T_{\alpha^+}^{\beta}(\UU^{\alpha}):\UU_{\beta}~(\alpha~\beta~\Level,\alpha^+\leqslant\beta)
$$
We introduce a new product operation
$$
\frac{t:A~(\psi)}{t:[\psi]A}
$$
with the elimination rule
$$
\frac{t:[\psi]A~~~~~~\psi}{t:A}
$$
Intuitively, we can use a term of type $[\psi]A$ only if the constraint $\psi$ holds.


\section{Solving universe constraints is polynomial}\label{sec:P-solvability}

We would need (for the Max-Atom algorithms to work):
\[
\vdash_{\cal L} l=m  \quad \quad \iff \quad \quad \mathbb{N},\rho \models l\rho = m\rho
\text{~~ for all $\rho$}
\]
and the type theory should have enough rules to ensure
\[
\vdash_{\cal L} l=m  \quad \quad \iff \quad \quad \vdash l=m
\text{~~ (judgmentally)}.
\]

The goal of the following is apply the methods from \cite{BNR08} to decide
the solvability of a finite set $S$ of universe constraints in polynomial time.
Here polynomial means polynomial in the total number $\mu(S)$ of occurrences of
variables and operations $\_^+$ and $\vee$ in $S$.

Let $S$ be a finite set of constraints of the form $l=m$ as in the previous section.
The \emph{level expressions} $l,m$ have the following abstract syntax:
\[
l,m,\ldots ::= {\alpha,\beta,\ldots} \mid {l^+} \mid {l\vee m}
\]
A \emph{model}, or \emph{solution} of $S$ is an assignment of natural numbers to
the level variables occurring in $S$ such that all constraints in $S$ become true
under the canonical interpretation of $\_^+$ as successor and $\vee$ as maximum.
Entailment under the canonical interpretation will be denoted by $\models$.

Solving $S$ can be reduced in polynomial time to solving a set $S'$ of
constraints of the form $\alpha\vee\beta = \gamma^+$, $\alpha\vee\beta = \gamma$,
and $(\alpha\vee\beta)^+ = \gamma$. Such forms are called \emph{reduced forms},
conveniently denoted by $(\alpha\vee\beta)+b = \gamma$, with $b=-1,0,1$.
If $\alpha=\beta$ we simply write $\alpha+b = \gamma$.

\begin{lemma}\label{lem:reduced-form}
For every finite set $S$ of constraints, there is a set $S'$ of
constraints in reduced form such that $S$ is solvable if and only if $S'$
is solvable. Furthermore, $S'$ contains precisely as many symbols $\_^+$ as $S$ does,
and $\mu(S')\leq 2\mu(S)$.
\end{lemma}

\begin{proof}
We first define by induction for any $l$ a fresh variable $v(l)$ and
a set $S(l)$ of constraints in reduced form such that $S(l)\models l = v(l)$.
In the base case we take $v(\alpha)=\alpha$ and $S(\alpha)$ empty, for any
level variable $\alpha$. In one step case we take $v(l^+)$ a fresh variable,
and $S(l^+) = S(l) \cup \set{v(l)^+ =v(l^+)}$.
In the other step case we take $v(l\vee m)$ again a fresh variable,
and $S(l\vee m) = S(l) \cup S(m) \cup \set{(v(l)\vee v(m)) =v(l\vee m)}$.
By induction we get $S(l)\models l = v(l)$, plus the following two facts.
First, $S(l)$ contains precisely as many symbols $\_^+$ as $l$ does,
and similarly for symbols $\vee$.
(Occurrences of such symbols in names of fresh variables do not count.)
Secondly, every assignment of variables occurring in $l$ can be extended to an
assignment validating $S(l)$.

Now consider a constraint $l=m$. Constraints of the form $l=l$ can
simply be removed. If $l$ and $m$ are distinct variables,
then we eliminate one of them by substitution. Otherwise,
we replace $l=m$ by $S(l)\cup S(m)\cup \set{v(l)=v(m)}$.
Doing this for all constraints in some given set $S$
leaves us with a set of constraints that are either in
reduced form, or of the form $v(l)=v(m)$ for distinct fresh variables.
The latter are easily removed by elimination. Let $S'$ be the resulting set
of constraints, which are all in reduced form. By the results on $S(l)$
and $v(l)$ from the previous paragraph, the set $S$ is solvable if
and only if $S'$ is solvable.

In terms of $\mu$-value, there is a small
difference between $S$ and $S'$ in the previous paragraph.
What happens during the reduction is that internal nodes
of parse trees of level expressions get labelled with fresh variables.
We get $\mu(S')\leq 2\mu(S)$ and the whole transformation, including the
elimination of variables, can certainly be done in quadratic time
(and probably better).
\end{proof}

We now prove a small model property.
\begin{lemma}\label{lem:small-model}
Let  $S$ be a finite set of constraints.
Let $K_{S}$ be the number of occurrences of symbols $\_^+$ in $S$.
If there is a model of $S$, then there is a model with values at most $K_{S}$.
\end{lemma}

\begin{proof}
%For any assignment $\rho$, define the \emph{range} of $\rho$ as the difference
%of the maximal value assigned to a variable by $\rho$ and the minimal value.
%For a subset of variables, we also speak about the range of that subset under $\rho$.
By \cref{lem:reduced-form} we may assume that $S$ is in reduced form.
Let $\rho$ be an assignment for the variables occurring in $S$.
We construct an undirected graph depending on $M$ and $\rho$.
The node set $V$ consists of all the variables occurring in $S$.
For every constraint  $(\alpha\vee\beta)+b = \gamma$,
if $\rho(\alpha)\geq \rho(\beta)$, then we add an edge between $\alpha$ and $\gamma$,
otherwise we add an edge between $\beta$ and $\gamma$.
The assignment $\rho$ maps the nodes in any connected component
\emph{surjectively} to a segment of the natural numbers, as $|b|\leq 1$.
The length of this segment is bounded by the number of symbols $\_^+$
in the constraints that define the connected component.

A \emph{gap} is given by two natural numbers $A<B$ such that:
\begin{enumerate}
\item $A=0$ or there is $\alpha\in V$ with $\rho(\alpha)=A$;
\item there is $\beta\in V$ with $\rho(\beta)=B$;
\item for all $\alpha\in V$ we have either $\rho(\alpha)\leq A$, or $B\leq\rho(\alpha)$;
\item for all $\alpha,\beta\in V$, if $\rho(\alpha)\leq A$ and $B\leq\rho(\beta)$,
then $\alpha$ and $\beta$ are not connected.
\end{enumerate}

Given a gap as above, we define an assignment $\rho'$ that closes the gap
such that $\rho'$ is a model of $S$ whenever $\rho$ is. We define
$\rho'(\alpha) = \rho(\alpha)$ if $\rho(\alpha)\leq A$,
and $\rho'(\alpha) = \rho(\alpha)+A-B$ otherwise, for every $\alpha\in V$.
Clearly, if $\alpha$ and $\gamma$ are connected, then they are by point 4
on the same side of the gap, and so $\rho(\alpha)-\rho'(\alpha) = \rho(\gamma)-\rho'(\gamma)$.
Moveover, if $\rho(\alpha)\geq\rho(\beta)$, then $\rho'(\alpha)\geq \rho'(\beta)$.
Hence $\rho'\models (\alpha\vee\beta)+b = \gamma$
if $\rho\models (\alpha\vee\beta)+b = \gamma$.
So $\rho'\models S$ whenever $\rho\models S$.

Iterating this procedure, starting from a model $M$ of $S$,
we can close all gaps and end up with a model with no gaps.
In this model the lowest value is $0$ (there is no gap $0<B$),
and the highest value of a variable is at most $K_S$.
The latter follows from the observation that the highest
value is at most the sum of the lengths of the (overlapping) segments
coming from the connected components, and this sum is bounded by $K_S$.
\end{proof}

\cref{lem:small-model} implies the decidability of solvability,
and we will now describe an efficient search procedure finding a
model if there exists one. We prepare by the following lemma.

\begin{lemma}\label{lem:model-search}
Assume $S$ is in reduced form.
Let $M$ be a model of $S$ and $\rho$ an assignment such that $\rho\geq M$ (pointwise).
If $\rho$ is not a model of $S$, then we have $\rho'\geq M$ for any assignment $\rho'$
that is obtained from $\rho$ in one of the following ways:
\begin{itemize}
\item Pick a constraint $(\alpha\vee\beta)+b = \gamma$ from $S$ with
$(\alpha\vee\beta)\rho +b+n = \gamma\rho$ for some $n>0$ and
define $\rho'(\gamma) = \rho(\gamma)-n$.
\item Pick a constraint $(\alpha\vee\beta)+b = \gamma$ from $S$ with
$(\alpha\vee\beta)\rho +b = \gamma\rho + n$ for some $n>0$ and
define $\rho'(\alpha) = \rho(\alpha)-n$ if $\rho(\alpha)\geq\rho(\beta)$.
\item Pick a constraint $(\alpha\vee\beta)+b = \gamma$ from $S$ with
$(\alpha\vee\beta)\rho +b = \gamma\rho + n$ for some $n>0$ and
define $\rho'(\beta) = \rho(\beta)-n$ if $\rho(\alpha)<\rho(\beta)$.
\end{itemize}
In all three cases, $\rho'$ assigns a lower value than $\rho$ to exactly one variable,
and keeps the same value as $\rho$ for all other variables.
\end{lemma}


\begin{proof}
Let conditions be as above. In each of the three cases we
have to prove that $\rho'\geq M$ for the only variable that is lowered.
We use that $\max$ is monotone in both its arguments.
\begin{itemize}
\item Assume
$(\alpha\vee\beta)\rho +b+n = \gamma\rho$ for some $n>0$.
Then $\rho'(\gamma) = \rho(\gamma)-n = (\alpha\vee\beta)\rho + b \geq
\max(M(\alpha),M(\beta)) +b = M(\gamma)$.
\item Assume
$(\alpha\vee\beta)\rho +b = \gamma\rho + n$ for some $n>0$, and
$\rho(\alpha)\geq\rho(\beta)$.
Then $\rho'(\alpha) = \rho(\alpha)-n = (\alpha\vee\beta)\rho -n =
\gamma\rho - b \geq M(\gamma)-b = \max(M(\alpha),M(\beta)) \geq M(\alpha)$.
\item Analogous to the previous case, but with $\rho(\alpha)<\rho(\beta)$
and $\rho'(\beta)=\rho(\beta)-n$.
\end{itemize}
Note that the proof is correct also if two or three of $\alpha,\beta,\gamma$
are equal.
\end{proof}

Assume $S$ is in reduced form. By \cref{lem:small-model},
if $S$ has a model, there is a model $M \leq K_S$.
We start the search from the assignment $\rho$ that is constant $K_S$.
In each step from $\rho$ to $\rho'$ in \cref{lem:model-search},
exactly one variable is lowered. This can be done at most $V K_S$ times,
where $V$ is the number of variables. So we will actually find the unique maximal
model $M$ with values at most $K_S$, if there is a model at all.
Each step requires a pass through all
all constraints to evaluate them in the current assignment.
When properly implemented this can be done in $O(K_S)$ time.
The whole decision procedure of first transforming to constraints in reduced
form and then testing for solvability would take $O(V K^2_S)$ time.
(It may be possible to do better.) We have certainly reached our goal:

\begin{theorem}\label{thm:P-solvability}
Deciding solvability of a finite set of universe constraints is polynomial.
\end{theorem}

\subsection*{Martin's example (Berry-like function)}

Here is an example of a problem if we want typical ambiguity in the absence of cumulativity.

[[The type constructor ``$\simeq$'' should be replaced by the identity type for this to work. I am not sure which notation for the identity type we want to use to formulate this example.]]

Consider the theorem
$$
    (A B : ?) \to A \times B \simeq B \times A
$$
The most general solution is $(A : \UU_l) (B : \UU_m)$ for $\UU_l$ and $\UU_m$ arbitrary.

Now  consider the theorem
$$
    (A B C : ?) \to A \times B \simeq C \times A \to B \times A \simeq C \times A
$$
If we write
$$
    (A : \UU_l) (B : \UU_m) (C : \UU_n) \to A \times B \simeq C \times A \to B \times A \simeq C \times A,
$$
we need to solve the system of equations
$$
    \UU_l \vee \UU_n = \UU_{l \vee m}
$$
$$
    \UU_l \vee \UU_n = \UU_{l \vee m}
$$
Hence three "maximally general" solutions are
$$
    (A : \UU_l ) (B : \UU_m ) (C : \UU_{l \vee m} )
$$
$$
    (A : \UU_l ) (B : \UU_{l \vee m }) (C : \UU_m )
$$
$$
    (A : \UU_l \vee \UU_m ) (B : \UU_l) (C : \UU_m )
$$
for $\UU_l$ and $\UU_m$ arbitrary.

\section{Related work}

Harper and Pollack \cite{HarperP91} consider the system $\CComega$, the Calculus of Constructions with an sequence of universes \`a la Russell. They consider both an externally indexed version and a version with level expressions which are either numbers or variables, and with constraints of the form $l < m$ and $l \leq m$. Chan has an algorithm for solving those constraints in $\Ordo(c,v^3)$, where $c$ is the number of constraints and $v$ is the number of level variables. They also consider the level synthesis problem in a version with an anonymous universe Type.

Huet, in an unpublished manuscript \cite{Huet87}, has independently developed an
algorithm for handling universes in the Calculus of Constructions. His approach is to drop the assumption that the universes form a linearly-ordered
cumulative hierarchy indexed by the natural numbers, and to consider instead a family of calculi in which there is some well-founded partial ordering
of universes. The input language is correspondingly restricted so that specific universes are disallowed; only the anonymous universe Type may be
used. The principal advantage of this approach over the one considered here
is that the consistency checking algorithm is significantly more efficient than
Chan's algorithm, reducing to an acyclicity check in a dependency graph of
universe levels. (cut-and-paste from Harper and Pollack)

Assaf \cite{Assaf14} considers an alternative version of the calculus of
constructions where subtyping is explicit. This new system avoids problems related to coercions and dependent types by using the Tarski style
of universes and by introducing additional equations to reflect equality. In particular he adds an explicit cumulativity map $\T^0_1 : \UU_0 \to \UU_1$. He argues that "full reflection" is necessary to achieve the expressivity of Russell style. He introduces the explicit cumulative calculus of constructions (CC$\uparrow$) which is closely related to our system of externally indexed Tarski style universes.

\section*{The problem of universes}

Some questions to be explored

\medskip

injective : $[\alpha](\UU_{\alpha^+}\rightarrow \UU_{\alpha^+})$ if we have only one level

Super universe? Solution with a 2 level type system

Constraint problems: is there a Finite number of most general solutions?

E.g. system $(l\vee m) = n^+$, system $l\vee m  = l\vee n$

If we have a function $f:[\alpha](\UU_{\alpha}\rightarrow \UU_{\alpha^+})$ we cannot iterate
this function internally, for instance  $f = \lam{\alpha}{\lambda (X:\UU_{\alpha})~X\rightarrow\UU_{\alpha}}$

\bibliographystyle{plain}
\bibliography{refs}
%\thebibliography

%\bibitem{VV}
%  V. Voevodsky
%  \newblock{Universe polymorphic type system.}
%  \newblock{Manuscript, 2014}
%
%\bibitem{BNR08}
%M.A.~Bezem, R.~Nieuwenhuis and E.~Rodr\'iguez.
%\newblock{The Max-Atom Problem and its Relevance}.
%In I.~Cervesato, H.~Veith and A.~Voronkov, editors,
%\emph{Proceedings LPAR-15}, LNAI 5330,
%pages 47--62, Springer-Verlag, Berlin, 2008.

%% \bibitem{Abel}
%% A. Abel and G. Scherer.
%% \newblock{On Irrelevance and Algorithmic Equality in Predicative Type Theory.}
%% \newblock{In Logical Methods in Computer Science, 8(1):1-36, 2012.}

%% \bibitem{Aczel}
%% P. Aczel.
%% \newblock{On Relating Type Theories and Set Theories.}
%% \newblock{{\em Types for proofs and programs}, 1–18, Lecture Notes in Comput. Sci., 1657, 1999.}

%% \bibitem{AK}
%% Th. Altenkirch and A. Kaposi.
%% \newblock{Normalisation by Evaluation for Dependent Type Theory.}
%% \newblock{FSCD, 2016.}

%% \bibitem{AHS}
%% Th. Altenkirch, M. Hofmann and Th. Streicher.
%% \newblock{Reduction-free normalisation for system F.}
%% \newblock{Unpublished note, 1997.}

%% \bibitem{BJ}
%% J.-Ph. Bernardy, P. Jansson, R. Paterson.
%% \newblock{Parametricity and dependent types.}
%% \newblock{ ICFP 2010: 345-356.}

%% \bibitem{BS}
%% U. Berger and H. Schwichtenberg.
%% \newblock{An inverse of the evaluation functional for typed lambda-calculus.}
%% \newblock{Proceedings of LICS 1991.}

%% \bibitem{Bickford}
%% M. Bickford.
%% \newblock{Formalizing Category Theory and Presheaf Models of Type Theory in Nuprl.}
%% \newblock{Preprint, https://arxiv.org/abs/1806.06114, 2018.}

%% %% \bibitem{CD}
%% %% Th. Coquand and P. Dybjer.
%% %% \newblock{Intuitionistic Model Constructions and Normalization Proofs.}
%% %% \newblock{Mathematical Structures in Computer Science 7(1): 75-94 (1997).}

%% \bibitem{Coq}
%% Th. Coquand.
%% \newblock{An algorithm for testing conversion in type theory.}
%% \newblock{In {\em Logical frameworks}, p. 255-279, Cambridge University Press, 1991.}

%% \bibitem{CCHM}
%% C. Cohen, Th. Coquand, S. Huber, A. M\"ortberg.
%% \newblock{Cubical type theory: a constructive interpretation of the univalence axiom.}
%% \newblock{Proceeding of the Type Conference, 2015.}

%% \bibitem{Rathjen}
%% L. Crosilla and ML. Rathjen
%% \newblock{Inaccessible set axioms may have little consistency strength.}
%% \newblock{Ann. Pure Appl. Log. 115, 33–70 (2002).}

%% \bibitem{Dybjer}
%% P. Dybjer.
%% \newblock{Internal Type Theory.}
%% \newblock{in {\em Types for Programs and Proofs}, Springer, 1996.}

%% %% \bibitem{Fiore}
%% %% M. Fiore, G. Pltokin and D. Turi.
%% %% \newblock{Abstract Syntax and Variable Binding.}
%% %% \newblock{Proc.\ 14$^{\rm th}$ LICS Conf., 1999.}

%% \bibitem{FLD}
%% S. Fortune, D. Leivant, M. O'Donnell.
%% \newblock{The Expressiveness of Simple and Second-Order Type Structures.}
%% \newblock{Journal of the ACM, Volume 30 Issue 1, p. 151-185, 1983.}

%% \bibitem{Godel}
%% K. G\"odel.
%% \newblock{\"Uber eine bisher noch nicht ben\"utzte Erweiterung des finiten Standpunktes.}
%% \newblock{Dialectica, 12, pp. 280-287, 1958.}

%% \bibitem{Hofmann1}
%% M. Hofmann.
%% \newblock{Syntax and semantics of dependent type theory.}
%% \newblock{In {\em Semantics of Logic of Computation}, Cambridge University Press, 1997.}

%% %% \bibitem{Hofmann}
%% %% M. Hofmann.
%% %% \newblock{Semantics analysis of higher-order syntax.}
%% %% \newblock{Proc.\ 14$^{\rm th}$ LICS Conf., 1999.}

%% \bibitem{LS}
%% J. Lambek and P.J. Scott.
%% \newblock{{\it Introduction to higher order categorical logic.}}
%% \newblock{Cambridge studies in advanced mathematics 7, 1986.}


%% \bibitem{ML72}
%% P. Martin-L\"of.
%% \newblock{An intuitionistic theory of types.}
%% \newblock{Preliminary version 1972; published in {\em 25 Years of Type Theory}, 1995.}

%% \bibitem{ML73}
%% P. Martin-L\"of.
%% \newblock{An intuitionistic theory of types: predicative part.}
%% \newblock{Logic Colloquium '73 (Bristol, 1973), pp. 73–118.}

%% \bibitem{ML74}
%% P. Martin-L\"of.
%% \newblock{About Models for Intuitionistic Type Theories and the Notion of Definitional Equality.}
%% \newblock{Proceedings of the Third Scandinavian Logic Symposium, 1975, Pages 81-109.}

%% \bibitem{ML79}
%% P. Martin-L\"of.
%% \newblock{Constructive mathematics and computer programming.}
%% \newblock{Logic, methodology and philosophy of science, VI (Hannover, 1979),  pp. 153--175,
%%  Stud. Logic Found. Math., 104, North-Holland, Amsterdam, 1982.}

%% \bibitem{Shoenfield}
%% J.R. Shoenfield.
%% \newblock{{\em Mathematical Logic.}}
%% \newblock{Addison-Wesley, 1967.}

%% \bibitem{Shulman}
%% M. Shulman.
%% \newblock{Univalence for inverse diagrams and homotopy canonicity.}
%% \newblock{{\em Mathematical Structures in Computer Science}, 25:05, p. 1203–1277, 2014.}

%% \bibitem{Tait}
%% W.W. Tait.
%% \newblock{Intensional interpretations of functionals of finite type, part I.}
%% \newblock{Journal of Symbolic Logic, 32, pp. 198-212, 1967.}



%\end{thebibliography}


\end{document}
