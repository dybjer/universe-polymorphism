
\documentclass{easychair}

\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage{latexsym}
\usepackage{amssymb,amstext,amsmath,amsthm}


\newcommand{\Id}{\mathsf{Id}}
\newcommand{\conv}{=}
%\newcommand{\conv}{\mathsf{conv}}
\newcommand{\lam}[2]{{\langle}#1{\rangle}#2}
\def\NN{\mathsf{N}}
\def\UU{\mathsf{U}}
\def\JJ{\mathsf{J}}
\def\Level{\mathsf{Level}}
%\def\Type{\hbox{\sf Type}}
\def\ZERO{\mathsf{0}}
\def\SUCC{\mathsf{S}}

\newcommand{\type}{\mathsf{type}}
\newcommand{\mypi}[3]{\Pi_{#1:#2}#3}
\newcommand{\mylam}[3]{\lambda_{#1:#2}#3}
\newcommand{\mysig}[3]{\Sigma_{#1:#2}#3}
\newcommand{\N}{\mathsf{N}}
\newcommand{\Set}{\mathsf{Set}}
\newcommand{\El}{\mathsf{El}}
%\newcommand{\U}{\mathsf{U}} clashes with def's in new packages
\newcommand{\T}{\mathsf{T}}
\newcommand{\Usuper}{\UU_{\mathrm{super}}}
\newcommand{\Tsuper}{\T_{\mathrm{super}}}
%\newcommand{\conv}{\mathrm{conv}}
\newcommand{\idtoeq}{\mathsf{idtoeq}}
\newcommand{\isEquiv}{\mathsf{isEquiv}}
\newcommand{\ua}{\mathsf{ua}}
\newcommand{\UA}{\mathsf{UA}}
%\newcommand{\Level}{\mathrm{Level}}
\newcommand{\natrec}{\mathsf{natrec}}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\sct}[1]{[\![#1]\!]}
\newcommand{\ttt}[1]{\text{\tt #1}}



\title{Type Theories with Universe Level Judgments}

\author{
  Marc Bezem\inst{1}
\and
  Thierry Coquand\inst{3}
\and
  Peter Dybjer\inst{3}
\and
  Mart\'in Escard\'o\inst{2}
}

\institute{
  University of Bergen, Norway
\and
  University of Birmingham, United Kingdom
\and
  Chalmers University of Technology,
  Gothenburg, Sweden
}

\titlerunning{}
\authorrunning{}


\begin{document}
\maketitle
%\date{}


%\section*{}\label{sec:intros}

\paragraph{History and state of the art.} 
The system of simple type theory, as introduced by Church \cite{church:formulation},
is elegant and forms the basis of several proof assistants. 
However, it has some unnatural limitations: it is not possible in this system to talk
about an arbitrary type, or about an arbitrary structure. 
It is also not possible to form the collection of e.g.\ all groups, 
as needed in category theory. In order to address these limitations, 
Martin-L\"of \cite{ML71,ML71a} introduced a system with a type $V$ of all types. 
A function $A\rightarrow V$ in this system can then be seen as a family of types 
over a given type $A$, and it is natural in such a system to refine
the operations of simple type theory, exponential and cartesian product, 
to operations of dependent products and sums. 
After the discovery of Girard's paradox in \cite{Girard71}, 
Martin-L\"of \cite{ML72} introduced a distinction between
{\em small} and {\em large} types, similar to the distinction introduced 
in category theory between large and small sets,
and the type $V$ became the (large) type of small types.
The name ``universe'' for such a type was chosen in analogy with the notion of 
universes introduced by Grothendieck to represent category theory in set theory.

Later, Martin-L\"of \cite{martinlof:predicative} introduced a countable tower 
of universes $\UU_0 : \UU_1 : \UU_2 : \cdots$.
We refer to the indices $0, 1, 2, \ldots$ as {\em universe levels}. 

Before the advent of univalent foundations, most type theorists expected only the first few 
universe levels to be relevant in practical formalisations. 
This included the expectation that it might be feasible for a user of type theory to 
explicitly assign universe levels to their types, simply adding updated versions of earlier
definitions when they were needed at different levels.
However, the number of copies of definitions does not only grow with the level, 
but also with the number of type arguments in the definition of a type former. 
(The latter growth can be exponential!)

 To deal with this problem Huet \cite{Huet87} and
 Harper and Pollack \cite{HarperP91} and, in Coq, Sozeau and Tabareau 
 \cite{SozeauTabareau:coq} introduced {\em universe polymorphism}.
 Their "implicit" approach to universe polymorphisms is, however, problematic 
 w.r.t.\ modularity, as pointed out in \cite{Courant02,Simpson04}: 
 one can prove $A\rightarrow B$ in one file, and $B\rightarrow C$ in one other file, while
$A\rightarrow C$ is not valid. In order to cope with this issue, J. Courant \cite{Courant02}
suggested to have explicit level universes, with a sup operation (see also \cite{herbelin05}).
This approach is now followed in Agda and in Voevodsky's proposal \cite{VV}.

With the advent of Voevodsky's univalent foundations, the need for universe polymorphism 
has only increased, see for example \cite{VV}. 
%One often wants to prove theorems uniformly for any arbitrary universe(s).
The {\em univalence axiom} states that for any two types $X,Y$ the canonical map
$$
\idtoeq_{X,Y} : (X=Y)\to (X\simeq Y)
$$
is an equivalence.
Formally, the univalence axiom is an axiom scheme which is added to Martin-Löf type theory. 
If we work in Martin-Löf type theory with a countable tower of universes, 
each type is a member of some universe $\UU_n$. 
Such a universe $\UU_n$ is {\em univalent} provided for all $X,Y : \UU_n$ the 
canonical map $\idtoeq_{X,Y}$ is an equivalence. 
Let $\UA_n$ be the type expressing the univalence of $\UU_n$, and let
$\ua_n : \UA_n$ for $n = 0,1,\ldots$ be a sequence of constants postulating 
the respective instances of the univalence axiom. 
We note that $X = Y : \UU_{n+1}$ and $X\simeq Y : \UU_n$ and hence $\UA_n$ is in $\UU_{n+1}$.
If we have a type of levels, as in Agda \cite{agda-manual} or Lean \cite{moura:lean},
we can express universe polymorphism as quantification over universe levels.

We remark that universes are more important in a predicative framework 
than in an impredicative one.
Consider for example the formalisation of real numbers as Dedekind cuts, 
or domain elements as filters of formal neighbourhoods, 
which belong to $\UU_1$ since they are properties of elements in $\UU_0$.
However, even in a system using an impredicative universe of propositions,
such as the ones in \cite{Huet87,moura:lean}, there is a need for the use of 
definitions parametric in universe levels.

\paragraph{Our contribution.}
  The goal of this work is to complement the proposals by Courant \cite{Courant02}
  and Voevodsky \cite{VV} by handling constraints on universe levels 
  and having instantiation operations.
  We start by giving the rules for a basic version of dependent type theory with
  $\Pi, \Sigma, \NN$, and an identity type former $\Id$.
  We then explain how to add an externally indexed countable sequence of 
  universes $\UU_n, \T_n$ \`a la Tarski with or without cumulativity rules. 
  
  We introduce then an internal notion of universe level and
  add two new judgment forms: $l\ \Level$ meaning that $l$ is a universe level, 
  and $l = m$ meaning that $l$ and $m$ are equal universe levels. 
  Here level expressions are built up from level variables $\alpha$ 
  using a successor operation $l^+$ and 
  a join (supremum, maximum) operation $l \vee m$.
  We let judgments depend not only on a context of ordinary variables, 
  but also on a list of level variables $\alpha_1, \ldots, \alpha_k$, 
  giving rise to a theory with level polymorphism.
  Certain typing rules are conditional on judgments of the form $l=m$. 
  This is a kind of ML-polymorphism since we only quantify over global level variables. 
  
  We then extend the above type theory with formation rules for level-indexed product 
  types $[\alpha]A$ meaning ``$A$ is a type for all universe levels $\alpha$".
  Furthermore, introduction and elimination rules for such types are given,
  as well as some new computational rules. An example that uses level-indexed products 
  is the following type which  expresses the theorem that univalence for universes 
  of arbitrary level implies function extensionality for functions between 
  universes of arbitrary levels.
$$
([\alpha]\mathsf{IsUnivalent}\, \UU_\alpha)
\to [\beta][\gamma] \mathsf{FunExt}\, \UU_\beta\, \UU_\gamma
$$

We also present (a variation of) Voevodsky's proposal \cite{VV} with level constraints,
complementing his proposal with a way to instantiate universe polymorphic
constants introduced with level variables and constraints.
  We shortly discuss the decision problems for sup-semilattices with
  successor that come with this approach. These problems can be solved 
  in polynomial time, as shown in \cite{bezem-coquand:lattices}.
  
  \medskip
  
As an example, we can define in our system a constant
$$
c~:\equiv~\lam{\alpha~\beta}\lambda_{Y:\UU_{\beta}}\Id~{\UU_{\beta}}~Y~ (\Sigma_{X:\UU_{\alpha}}X\rightarrow Y)~~:~~
   [\alpha~\beta][\alpha<\beta]\UU_{\beta} \rightarrow \UU_{\beta^+},
$$
since $\Sigma_{X:\UU_{\alpha}}X\rightarrow Y$ has type $\UU_{\beta}$ in the context
   $$\alpha:\Level,~\beta:\Level,~\alpha<\beta,~Y:\UU_{\beta}.$$
We can instantiate this constant $c$ with two levels $l$ and $m$, 
   and this will be of type
   $$[l<m]\UU_{m} \rightarrow \UU_{m^+},$$
which only can be used if $l<m$ holds in the current context.

   \medskip

In the current system of Agda \cite{agda-manual}, 
the constraint $\alpha<\beta$ is represented indirectly by
writing $\beta$ in the form $\gamma\vee \alpha^+$ and $c$ is defined as
$$
c~:\equiv~\lam{\alpha~\gamma}\lambda_{Y:\UU_{\alpha^+\vee\gamma}}\Id~{\UU_{\alpha^+\vee\gamma}}~Y~ (\Sigma_{X:\UU_{\alpha}}X\rightarrow Y)~~:~~
   [\alpha~\gamma]\UU_{\alpha^+\vee\gamma} \rightarrow \UU_{\alpha^{++}\vee\gamma^+},
$$
   which arguably is less readable. Moreover, not all constraints that occur in practice
   can be expressed in this way.


\bibliographystyle{plain}
\bibliography{refs}

\end{document}
